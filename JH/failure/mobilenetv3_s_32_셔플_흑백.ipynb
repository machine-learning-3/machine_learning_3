{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import math\n",
        "import os"
      ],
      "metadata": {
        "id": "RJqq2BV4Uhk2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac2gOdaA3qyd",
        "outputId": "973b98f2-06de-40ea-dfb7-d9356d8337bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    seed = 42\n",
        "    device = \"cuda:0\"    \n",
        "        \n",
        "    lr = 1e-3\n",
        "    epochs = 25\n",
        "    batch_size = 32\n",
        "    num_workers = 4\n",
        "    train_5_folds = True\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "seed_everything(config.seed)"
      ],
      "metadata": {
        "id": "3vyQQ0rYqwp9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnZf8_DlJRxC",
        "outputId": "6cb370b1-7176-40ec-f90d-35bce0b60c12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "transform_train = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                      transforms.RandomVerticalFlip(p=0.5),\n",
        "                                      transforms.RandomGrayscale(p=1)])\n",
        "\n",
        "transform_validation = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomGrayscale(p=1)])\n",
        "\n",
        "transform  = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomGrayscale(p=1)])"
      ],
      "metadata": {
        "id": "X3YUvobnJimS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=True,\n",
        "                                        download=False,\n",
        "                                        transform=transform_train)\n",
        "\n",
        "vaildset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=False,\n",
        "                                        download=False,\n",
        "                                        transform=transform_validation)"
      ],
      "metadata": {
        "id": "hz66n6zuOikG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.ImageFolder(root = \"/content/drive/MyDrive/share/images/Statistical_Deep_Image\",\n",
        "                                           transform = transform)"
      ],
      "metadata": {
        "id": "Zd8-9_oDSQK_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(trainset,\n",
        "                          batch_size = 16,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "vaild_loader = DataLoader(vaildset,\n",
        "                          batch_size = 64,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "\n",
        "test_loader = DataLoader(testset,\n",
        "                          batch_size=64,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)"
      ],
      "metadata": {
        "id": "JRxWLJjnKUIt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "import timm\n",
        "\n",
        "\n",
        "timm.list_models()\n"
      ],
      "metadata": {
        "id": "NkV4EfO4VplZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87dada56-f813-4ea0-99c7-2b0854961809"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 36.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 75.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->timm) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.10.1 timm-0.6.11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adv_inception_v3',\n",
              " 'bat_resnext26ts',\n",
              " 'beit_base_patch16_224',\n",
              " 'beit_base_patch16_224_in22k',\n",
              " 'beit_base_patch16_384',\n",
              " 'beit_large_patch16_224',\n",
              " 'beit_large_patch16_224_in22k',\n",
              " 'beit_large_patch16_384',\n",
              " 'beit_large_patch16_512',\n",
              " 'beitv2_base_patch16_224',\n",
              " 'beitv2_base_patch16_224_in22k',\n",
              " 'beitv2_large_patch16_224',\n",
              " 'beitv2_large_patch16_224_in22k',\n",
              " 'botnet26t_256',\n",
              " 'botnet50ts_256',\n",
              " 'cait_m36_384',\n",
              " 'cait_m48_448',\n",
              " 'cait_s24_224',\n",
              " 'cait_s24_384',\n",
              " 'cait_s36_384',\n",
              " 'cait_xs24_384',\n",
              " 'cait_xxs24_224',\n",
              " 'cait_xxs24_384',\n",
              " 'cait_xxs36_224',\n",
              " 'cait_xxs36_384',\n",
              " 'coat_lite_mini',\n",
              " 'coat_lite_small',\n",
              " 'coat_lite_tiny',\n",
              " 'coat_mini',\n",
              " 'coat_tiny',\n",
              " 'coatnet_0_224',\n",
              " 'coatnet_0_rw_224',\n",
              " 'coatnet_1_224',\n",
              " 'coatnet_1_rw_224',\n",
              " 'coatnet_2_224',\n",
              " 'coatnet_2_rw_224',\n",
              " 'coatnet_3_224',\n",
              " 'coatnet_3_rw_224',\n",
              " 'coatnet_4_224',\n",
              " 'coatnet_5_224',\n",
              " 'coatnet_bn_0_rw_224',\n",
              " 'coatnet_nano_cc_224',\n",
              " 'coatnet_nano_rw_224',\n",
              " 'coatnet_pico_rw_224',\n",
              " 'coatnet_rmlp_0_rw_224',\n",
              " 'coatnet_rmlp_1_rw_224',\n",
              " 'coatnet_rmlp_2_rw_224',\n",
              " 'coatnet_rmlp_3_rw_224',\n",
              " 'coatnet_rmlp_nano_rw_224',\n",
              " 'coatnext_nano_rw_224',\n",
              " 'convit_base',\n",
              " 'convit_small',\n",
              " 'convit_tiny',\n",
              " 'convmixer_768_32',\n",
              " 'convmixer_1024_20_ks9_p14',\n",
              " 'convmixer_1536_20',\n",
              " 'convnext_atto',\n",
              " 'convnext_atto_ols',\n",
              " 'convnext_base',\n",
              " 'convnext_base_384_in22ft1k',\n",
              " 'convnext_base_in22ft1k',\n",
              " 'convnext_base_in22k',\n",
              " 'convnext_femto',\n",
              " 'convnext_femto_ols',\n",
              " 'convnext_large',\n",
              " 'convnext_large_384_in22ft1k',\n",
              " 'convnext_large_in22ft1k',\n",
              " 'convnext_large_in22k',\n",
              " 'convnext_nano',\n",
              " 'convnext_nano_ols',\n",
              " 'convnext_pico',\n",
              " 'convnext_pico_ols',\n",
              " 'convnext_small',\n",
              " 'convnext_small_384_in22ft1k',\n",
              " 'convnext_small_in22ft1k',\n",
              " 'convnext_small_in22k',\n",
              " 'convnext_tiny',\n",
              " 'convnext_tiny_384_in22ft1k',\n",
              " 'convnext_tiny_hnf',\n",
              " 'convnext_tiny_in22ft1k',\n",
              " 'convnext_tiny_in22k',\n",
              " 'convnext_xlarge_384_in22ft1k',\n",
              " 'convnext_xlarge_in22ft1k',\n",
              " 'convnext_xlarge_in22k',\n",
              " 'crossvit_9_240',\n",
              " 'crossvit_9_dagger_240',\n",
              " 'crossvit_15_240',\n",
              " 'crossvit_15_dagger_240',\n",
              " 'crossvit_15_dagger_408',\n",
              " 'crossvit_18_240',\n",
              " 'crossvit_18_dagger_240',\n",
              " 'crossvit_18_dagger_408',\n",
              " 'crossvit_base_240',\n",
              " 'crossvit_small_240',\n",
              " 'crossvit_tiny_240',\n",
              " 'cs3darknet_focus_l',\n",
              " 'cs3darknet_focus_m',\n",
              " 'cs3darknet_focus_s',\n",
              " 'cs3darknet_focus_x',\n",
              " 'cs3darknet_l',\n",
              " 'cs3darknet_m',\n",
              " 'cs3darknet_s',\n",
              " 'cs3darknet_x',\n",
              " 'cs3edgenet_x',\n",
              " 'cs3se_edgenet_x',\n",
              " 'cs3sedarknet_l',\n",
              " 'cs3sedarknet_x',\n",
              " 'cs3sedarknet_xdw',\n",
              " 'cspdarknet53',\n",
              " 'cspresnet50',\n",
              " 'cspresnet50d',\n",
              " 'cspresnet50w',\n",
              " 'cspresnext50',\n",
              " 'darknet17',\n",
              " 'darknet21',\n",
              " 'darknet53',\n",
              " 'darknetaa53',\n",
              " 'deit3_base_patch16_224',\n",
              " 'deit3_base_patch16_224_in21ft1k',\n",
              " 'deit3_base_patch16_384',\n",
              " 'deit3_base_patch16_384_in21ft1k',\n",
              " 'deit3_huge_patch14_224',\n",
              " 'deit3_huge_patch14_224_in21ft1k',\n",
              " 'deit3_large_patch16_224',\n",
              " 'deit3_large_patch16_224_in21ft1k',\n",
              " 'deit3_large_patch16_384',\n",
              " 'deit3_large_patch16_384_in21ft1k',\n",
              " 'deit3_medium_patch16_224',\n",
              " 'deit3_medium_patch16_224_in21ft1k',\n",
              " 'deit3_small_patch16_224',\n",
              " 'deit3_small_patch16_224_in21ft1k',\n",
              " 'deit3_small_patch16_384',\n",
              " 'deit3_small_patch16_384_in21ft1k',\n",
              " 'deit_base_distilled_patch16_224',\n",
              " 'deit_base_distilled_patch16_384',\n",
              " 'deit_base_patch16_224',\n",
              " 'deit_base_patch16_384',\n",
              " 'deit_small_distilled_patch16_224',\n",
              " 'deit_small_patch16_224',\n",
              " 'deit_tiny_distilled_patch16_224',\n",
              " 'deit_tiny_patch16_224',\n",
              " 'densenet121',\n",
              " 'densenet121d',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'densenet264',\n",
              " 'densenet264d_iabn',\n",
              " 'densenetblur121d',\n",
              " 'dla34',\n",
              " 'dla46_c',\n",
              " 'dla46x_c',\n",
              " 'dla60',\n",
              " 'dla60_res2net',\n",
              " 'dla60_res2next',\n",
              " 'dla60x',\n",
              " 'dla60x_c',\n",
              " 'dla102',\n",
              " 'dla102x',\n",
              " 'dla102x2',\n",
              " 'dla169',\n",
              " 'dm_nfnet_f0',\n",
              " 'dm_nfnet_f1',\n",
              " 'dm_nfnet_f2',\n",
              " 'dm_nfnet_f3',\n",
              " 'dm_nfnet_f4',\n",
              " 'dm_nfnet_f5',\n",
              " 'dm_nfnet_f6',\n",
              " 'dpn68',\n",
              " 'dpn68b',\n",
              " 'dpn92',\n",
              " 'dpn98',\n",
              " 'dpn107',\n",
              " 'dpn131',\n",
              " 'eca_botnext26ts_256',\n",
              " 'eca_halonext26ts',\n",
              " 'eca_nfnet_l0',\n",
              " 'eca_nfnet_l1',\n",
              " 'eca_nfnet_l2',\n",
              " 'eca_nfnet_l3',\n",
              " 'eca_resnet33ts',\n",
              " 'eca_resnext26ts',\n",
              " 'eca_vovnet39b',\n",
              " 'ecaresnet26t',\n",
              " 'ecaresnet50d',\n",
              " 'ecaresnet50d_pruned',\n",
              " 'ecaresnet50t',\n",
              " 'ecaresnet101d',\n",
              " 'ecaresnet101d_pruned',\n",
              " 'ecaresnet200d',\n",
              " 'ecaresnet269d',\n",
              " 'ecaresnetlight',\n",
              " 'ecaresnext26t_32x4d',\n",
              " 'ecaresnext50t_32x4d',\n",
              " 'edgenext_base',\n",
              " 'edgenext_small',\n",
              " 'edgenext_small_rw',\n",
              " 'edgenext_x_small',\n",
              " 'edgenext_xx_small',\n",
              " 'efficientformer_l1',\n",
              " 'efficientformer_l3',\n",
              " 'efficientformer_l7',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b0_g8_gn',\n",
              " 'efficientnet_b0_g16_evos',\n",
              " 'efficientnet_b0_gn',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b1_pruned',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b2_pruned',\n",
              " 'efficientnet_b2a',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b3_g8_gn',\n",
              " 'efficientnet_b3_gn',\n",
              " 'efficientnet_b3_pruned',\n",
              " 'efficientnet_b3a',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_b8',\n",
              " 'efficientnet_cc_b0_4e',\n",
              " 'efficientnet_cc_b0_8e',\n",
              " 'efficientnet_cc_b1_8e',\n",
              " 'efficientnet_el',\n",
              " 'efficientnet_el_pruned',\n",
              " 'efficientnet_em',\n",
              " 'efficientnet_es',\n",
              " 'efficientnet_es_pruned',\n",
              " 'efficientnet_l2',\n",
              " 'efficientnet_lite0',\n",
              " 'efficientnet_lite1',\n",
              " 'efficientnet_lite2',\n",
              " 'efficientnet_lite3',\n",
              " 'efficientnet_lite4',\n",
              " 'efficientnetv2_l',\n",
              " 'efficientnetv2_m',\n",
              " 'efficientnetv2_rw_m',\n",
              " 'efficientnetv2_rw_s',\n",
              " 'efficientnetv2_rw_t',\n",
              " 'efficientnetv2_s',\n",
              " 'efficientnetv2_xl',\n",
              " 'ens_adv_inception_resnet_v2',\n",
              " 'ese_vovnet19b_dw',\n",
              " 'ese_vovnet19b_slim',\n",
              " 'ese_vovnet19b_slim_dw',\n",
              " 'ese_vovnet39b',\n",
              " 'ese_vovnet39b_evos',\n",
              " 'ese_vovnet57b',\n",
              " 'ese_vovnet99b',\n",
              " 'ese_vovnet99b_iabn',\n",
              " 'fbnetc_100',\n",
              " 'fbnetv3_b',\n",
              " 'fbnetv3_d',\n",
              " 'fbnetv3_g',\n",
              " 'gc_efficientnetv2_rw_t',\n",
              " 'gcresnet33ts',\n",
              " 'gcresnet50t',\n",
              " 'gcresnext26ts',\n",
              " 'gcresnext50ts',\n",
              " 'gcvit_base',\n",
              " 'gcvit_small',\n",
              " 'gcvit_tiny',\n",
              " 'gcvit_xtiny',\n",
              " 'gcvit_xxtiny',\n",
              " 'gernet_l',\n",
              " 'gernet_m',\n",
              " 'gernet_s',\n",
              " 'ghostnet_050',\n",
              " 'ghostnet_100',\n",
              " 'ghostnet_130',\n",
              " 'gluon_inception_v3',\n",
              " 'gluon_resnet18_v1b',\n",
              " 'gluon_resnet34_v1b',\n",
              " 'gluon_resnet50_v1b',\n",
              " 'gluon_resnet50_v1c',\n",
              " 'gluon_resnet50_v1d',\n",
              " 'gluon_resnet50_v1s',\n",
              " 'gluon_resnet101_v1b',\n",
              " 'gluon_resnet101_v1c',\n",
              " 'gluon_resnet101_v1d',\n",
              " 'gluon_resnet101_v1s',\n",
              " 'gluon_resnet152_v1b',\n",
              " 'gluon_resnet152_v1c',\n",
              " 'gluon_resnet152_v1d',\n",
              " 'gluon_resnet152_v1s',\n",
              " 'gluon_resnext50_32x4d',\n",
              " 'gluon_resnext101_32x4d',\n",
              " 'gluon_resnext101_64x4d',\n",
              " 'gluon_senet154',\n",
              " 'gluon_seresnext50_32x4d',\n",
              " 'gluon_seresnext101_32x4d',\n",
              " 'gluon_seresnext101_64x4d',\n",
              " 'gluon_xception65',\n",
              " 'gmixer_12_224',\n",
              " 'gmixer_24_224',\n",
              " 'gmlp_b16_224',\n",
              " 'gmlp_s16_224',\n",
              " 'gmlp_ti16_224',\n",
              " 'halo2botnet50ts_256',\n",
              " 'halonet26t',\n",
              " 'halonet50ts',\n",
              " 'halonet_h1',\n",
              " 'haloregnetz_b',\n",
              " 'hardcorenas_a',\n",
              " 'hardcorenas_b',\n",
              " 'hardcorenas_c',\n",
              " 'hardcorenas_d',\n",
              " 'hardcorenas_e',\n",
              " 'hardcorenas_f',\n",
              " 'hrnet_w18',\n",
              " 'hrnet_w18_small',\n",
              " 'hrnet_w18_small_v2',\n",
              " 'hrnet_w30',\n",
              " 'hrnet_w32',\n",
              " 'hrnet_w40',\n",
              " 'hrnet_w44',\n",
              " 'hrnet_w48',\n",
              " 'hrnet_w64',\n",
              " 'ig_resnext101_32x8d',\n",
              " 'ig_resnext101_32x16d',\n",
              " 'ig_resnext101_32x32d',\n",
              " 'ig_resnext101_32x48d',\n",
              " 'inception_resnet_v2',\n",
              " 'inception_v3',\n",
              " 'inception_v4',\n",
              " 'jx_nest_base',\n",
              " 'jx_nest_small',\n",
              " 'jx_nest_tiny',\n",
              " 'lambda_resnet26rpt_256',\n",
              " 'lambda_resnet26t',\n",
              " 'lambda_resnet50ts',\n",
              " 'lamhalobotnet50ts_256',\n",
              " 'lcnet_035',\n",
              " 'lcnet_050',\n",
              " 'lcnet_075',\n",
              " 'lcnet_100',\n",
              " 'lcnet_150',\n",
              " 'legacy_senet154',\n",
              " 'legacy_seresnet18',\n",
              " 'legacy_seresnet34',\n",
              " 'legacy_seresnet50',\n",
              " 'legacy_seresnet101',\n",
              " 'legacy_seresnet152',\n",
              " 'legacy_seresnext26_32x4d',\n",
              " 'legacy_seresnext50_32x4d',\n",
              " 'legacy_seresnext101_32x4d',\n",
              " 'levit_128',\n",
              " 'levit_128s',\n",
              " 'levit_192',\n",
              " 'levit_256',\n",
              " 'levit_256d',\n",
              " 'levit_384',\n",
              " 'maxvit_base_224',\n",
              " 'maxvit_large_224',\n",
              " 'maxvit_nano_rw_256',\n",
              " 'maxvit_pico_rw_256',\n",
              " 'maxvit_rmlp_nano_rw_256',\n",
              " 'maxvit_rmlp_pico_rw_256',\n",
              " 'maxvit_rmlp_small_rw_224',\n",
              " 'maxvit_rmlp_small_rw_256',\n",
              " 'maxvit_rmlp_tiny_rw_256',\n",
              " 'maxvit_small_224',\n",
              " 'maxvit_tiny_224',\n",
              " 'maxvit_tiny_pm_256',\n",
              " 'maxvit_tiny_rw_224',\n",
              " 'maxvit_tiny_rw_256',\n",
              " 'maxvit_xlarge_224',\n",
              " 'maxxvit_nano_rw_256',\n",
              " 'maxxvit_small_rw_256',\n",
              " 'maxxvit_tiny_rw_256',\n",
              " 'mixer_b16_224',\n",
              " 'mixer_b16_224_in21k',\n",
              " 'mixer_b16_224_miil',\n",
              " 'mixer_b16_224_miil_in21k',\n",
              " 'mixer_b32_224',\n",
              " 'mixer_l16_224',\n",
              " 'mixer_l16_224_in21k',\n",
              " 'mixer_l32_224',\n",
              " 'mixer_s16_224',\n",
              " 'mixer_s32_224',\n",
              " 'mixnet_l',\n",
              " 'mixnet_m',\n",
              " 'mixnet_s',\n",
              " 'mixnet_xl',\n",
              " 'mixnet_xxl',\n",
              " 'mnasnet_050',\n",
              " 'mnasnet_075',\n",
              " 'mnasnet_100',\n",
              " 'mnasnet_140',\n",
              " 'mnasnet_a1',\n",
              " 'mnasnet_b1',\n",
              " 'mnasnet_small',\n",
              " 'mobilenetv2_035',\n",
              " 'mobilenetv2_050',\n",
              " 'mobilenetv2_075',\n",
              " 'mobilenetv2_100',\n",
              " 'mobilenetv2_110d',\n",
              " 'mobilenetv2_120d',\n",
              " 'mobilenetv2_140',\n",
              " 'mobilenetv3_large_075',\n",
              " 'mobilenetv3_large_100',\n",
              " 'mobilenetv3_large_100_miil',\n",
              " 'mobilenetv3_large_100_miil_in21k',\n",
              " 'mobilenetv3_rw',\n",
              " 'mobilenetv3_small_050',\n",
              " 'mobilenetv3_small_075',\n",
              " 'mobilenetv3_small_100',\n",
              " 'mobilevit_s',\n",
              " 'mobilevit_xs',\n",
              " 'mobilevit_xxs',\n",
              " 'mobilevitv2_050',\n",
              " 'mobilevitv2_075',\n",
              " 'mobilevitv2_100',\n",
              " 'mobilevitv2_125',\n",
              " 'mobilevitv2_150',\n",
              " 'mobilevitv2_150_384_in22ft1k',\n",
              " 'mobilevitv2_150_in22ft1k',\n",
              " 'mobilevitv2_175',\n",
              " 'mobilevitv2_175_384_in22ft1k',\n",
              " 'mobilevitv2_175_in22ft1k',\n",
              " 'mobilevitv2_200',\n",
              " 'mobilevitv2_200_384_in22ft1k',\n",
              " 'mobilevitv2_200_in22ft1k',\n",
              " 'mvitv2_base',\n",
              " 'mvitv2_large',\n",
              " 'mvitv2_small',\n",
              " 'mvitv2_small_cls',\n",
              " 'mvitv2_tiny',\n",
              " 'nasnetalarge',\n",
              " 'nest_base',\n",
              " 'nest_small',\n",
              " 'nest_tiny',\n",
              " 'nf_ecaresnet26',\n",
              " 'nf_ecaresnet50',\n",
              " 'nf_ecaresnet101',\n",
              " 'nf_regnet_b0',\n",
              " 'nf_regnet_b1',\n",
              " 'nf_regnet_b2',\n",
              " 'nf_regnet_b3',\n",
              " 'nf_regnet_b4',\n",
              " 'nf_regnet_b5',\n",
              " 'nf_resnet26',\n",
              " 'nf_resnet50',\n",
              " 'nf_resnet101',\n",
              " 'nf_seresnet26',\n",
              " 'nf_seresnet50',\n",
              " 'nf_seresnet101',\n",
              " 'nfnet_f0',\n",
              " 'nfnet_f1',\n",
              " 'nfnet_f2',\n",
              " 'nfnet_f3',\n",
              " 'nfnet_f4',\n",
              " 'nfnet_f5',\n",
              " 'nfnet_f6',\n",
              " 'nfnet_f7',\n",
              " 'nfnet_l0',\n",
              " 'pit_b_224',\n",
              " 'pit_b_distilled_224',\n",
              " 'pit_s_224',\n",
              " 'pit_s_distilled_224',\n",
              " 'pit_ti_224',\n",
              " 'pit_ti_distilled_224',\n",
              " 'pit_xs_224',\n",
              " 'pit_xs_distilled_224',\n",
              " 'pnasnet5large',\n",
              " 'poolformer_m36',\n",
              " 'poolformer_m48',\n",
              " 'poolformer_s12',\n",
              " 'poolformer_s24',\n",
              " 'poolformer_s36',\n",
              " 'pvt_v2_b0',\n",
              " 'pvt_v2_b1',\n",
              " 'pvt_v2_b2',\n",
              " 'pvt_v2_b2_li',\n",
              " 'pvt_v2_b3',\n",
              " 'pvt_v2_b4',\n",
              " 'pvt_v2_b5',\n",
              " 'regnetv_040',\n",
              " 'regnetv_064',\n",
              " 'regnetx_002',\n",
              " 'regnetx_004',\n",
              " 'regnetx_006',\n",
              " 'regnetx_008',\n",
              " 'regnetx_016',\n",
              " 'regnetx_032',\n",
              " 'regnetx_040',\n",
              " 'regnetx_064',\n",
              " 'regnetx_080',\n",
              " 'regnetx_120',\n",
              " 'regnetx_160',\n",
              " 'regnetx_320',\n",
              " 'regnety_002',\n",
              " 'regnety_004',\n",
              " 'regnety_006',\n",
              " 'regnety_008',\n",
              " 'regnety_016',\n",
              " 'regnety_032',\n",
              " 'regnety_040',\n",
              " 'regnety_040s_gn',\n",
              " 'regnety_064',\n",
              " 'regnety_080',\n",
              " 'regnety_120',\n",
              " 'regnety_160',\n",
              " 'regnety_320',\n",
              " 'regnetz_005',\n",
              " 'regnetz_040',\n",
              " 'regnetz_040h',\n",
              " 'regnetz_b16',\n",
              " 'regnetz_b16_evos',\n",
              " 'regnetz_c16',\n",
              " 'regnetz_c16_evos',\n",
              " 'regnetz_d8',\n",
              " 'regnetz_d8_evos',\n",
              " 'regnetz_d32',\n",
              " 'regnetz_e8',\n",
              " 'repvgg_a2',\n",
              " 'repvgg_b0',\n",
              " 'repvgg_b1',\n",
              " 'repvgg_b1g4',\n",
              " 'repvgg_b2',\n",
              " 'repvgg_b2g4',\n",
              " 'repvgg_b3',\n",
              " 'repvgg_b3g4',\n",
              " 'res2net50_14w_8s',\n",
              " 'res2net50_26w_4s',\n",
              " 'res2net50_26w_6s',\n",
              " 'res2net50_26w_8s',\n",
              " 'res2net50_48w_2s',\n",
              " 'res2net101_26w_4s',\n",
              " 'res2next50',\n",
              " 'resmlp_12_224',\n",
              " 'resmlp_12_224_dino',\n",
              " 'resmlp_12_distilled_224',\n",
              " 'resmlp_24_224',\n",
              " 'resmlp_24_224_dino',\n",
              " 'resmlp_24_distilled_224',\n",
              " 'resmlp_36_224',\n",
              " 'resmlp_36_distilled_224',\n",
              " 'resmlp_big_24_224',\n",
              " 'resmlp_big_24_224_in22ft1k',\n",
              " 'resmlp_big_24_distilled_224',\n",
              " 'resnest14d',\n",
              " 'resnest26d',\n",
              " 'resnest50d',\n",
              " 'resnest50d_1s4x24d',\n",
              " 'resnest50d_4s2x40d',\n",
              " 'resnest101e',\n",
              " 'resnest200e',\n",
              " 'resnest269e',\n",
              " 'resnet10t',\n",
              " 'resnet14t',\n",
              " 'resnet18',\n",
              " 'resnet18d',\n",
              " 'resnet26',\n",
              " 'resnet26d',\n",
              " 'resnet26t',\n",
              " 'resnet32ts',\n",
              " 'resnet33ts',\n",
              " 'resnet34',\n",
              " 'resnet34d',\n",
              " 'resnet50',\n",
              " 'resnet50_gn',\n",
              " 'resnet50d',\n",
              " 'resnet50t',\n",
              " 'resnet51q',\n",
              " 'resnet61q',\n",
              " 'resnet101',\n",
              " 'resnet101d',\n",
              " 'resnet152',\n",
              " 'resnet152d',\n",
              " 'resnet200',\n",
              " 'resnet200d',\n",
              " 'resnetaa50',\n",
              " 'resnetaa50d',\n",
              " 'resnetaa101d',\n",
              " 'resnetblur18',\n",
              " 'resnetblur50',\n",
              " 'resnetblur50d',\n",
              " 'resnetblur101d',\n",
              " 'resnetrs50',\n",
              " 'resnetrs101',\n",
              " 'resnetrs152',\n",
              " 'resnetrs200',\n",
              " 'resnetrs270',\n",
              " 'resnetrs350',\n",
              " 'resnetrs420',\n",
              " 'resnetv2_50',\n",
              " 'resnetv2_50d',\n",
              " 'resnetv2_50d_evob',\n",
              " 'resnetv2_50d_evos',\n",
              " 'resnetv2_50d_frn',\n",
              " 'resnetv2_50d_gn',\n",
              " 'resnetv2_50t',\n",
              " 'resnetv2_50x1_bit_distilled',\n",
              " 'resnetv2_50x1_bitm',\n",
              " 'resnetv2_50x1_bitm_in21k',\n",
              " 'resnetv2_50x3_bitm',\n",
              " 'resnetv2_50x3_bitm_in21k',\n",
              " 'resnetv2_101',\n",
              " 'resnetv2_101d',\n",
              " 'resnetv2_101x1_bitm',\n",
              " 'resnetv2_101x1_bitm_in21k',\n",
              " 'resnetv2_101x3_bitm',\n",
              " 'resnetv2_101x3_bitm_in21k',\n",
              " 'resnetv2_152',\n",
              " 'resnetv2_152d',\n",
              " 'resnetv2_152x2_bit_teacher',\n",
              " 'resnetv2_152x2_bit_teacher_384',\n",
              " 'resnetv2_152x2_bitm',\n",
              " 'resnetv2_152x2_bitm_in21k',\n",
              " 'resnetv2_152x4_bitm',\n",
              " 'resnetv2_152x4_bitm_in21k',\n",
              " 'resnext26ts',\n",
              " 'resnext50_32x4d',\n",
              " 'resnext50d_32x4d',\n",
              " 'resnext101_32x4d',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'rexnet_100',\n",
              " 'rexnet_130',\n",
              " 'rexnet_150',\n",
              " 'rexnet_200',\n",
              " 'rexnetr_100',\n",
              " 'rexnetr_130',\n",
              " 'rexnetr_150',\n",
              " 'rexnetr_200',\n",
              " 'sebotnet33ts_256',\n",
              " 'sedarknet21',\n",
              " 'sehalonet33ts',\n",
              " 'selecsls42',\n",
              " 'selecsls42b',\n",
              " 'selecsls60',\n",
              " 'selecsls60b',\n",
              " 'selecsls84',\n",
              " 'semnasnet_050',\n",
              " 'semnasnet_075',\n",
              " 'semnasnet_100',\n",
              " 'semnasnet_140',\n",
              " 'semobilevit_s',\n",
              " 'senet154',\n",
              " 'sequencer2d_l',\n",
              " 'sequencer2d_m',\n",
              " 'sequencer2d_s',\n",
              " 'seresnet18',\n",
              " 'seresnet33ts',\n",
              " 'seresnet34',\n",
              " 'seresnet50',\n",
              " 'seresnet50t',\n",
              " 'seresnet101',\n",
              " 'seresnet152',\n",
              " 'seresnet152d',\n",
              " 'seresnet200d',\n",
              " 'seresnet269d',\n",
              " 'seresnetaa50d',\n",
              " 'seresnext26d_32x4d',\n",
              " 'seresnext26t_32x4d',\n",
              " 'seresnext26tn_32x4d',\n",
              " 'seresnext26ts',\n",
              " 'seresnext50_32x4d',\n",
              " 'seresnext101_32x4d',\n",
              " 'seresnext101_32x8d',\n",
              " 'seresnext101d_32x8d',\n",
              " 'seresnextaa101d_32x8d',\n",
              " 'skresnet18',\n",
              " 'skresnet34',\n",
              " 'skresnet50',\n",
              " 'skresnet50d',\n",
              " 'skresnext50_32x4d',\n",
              " 'spnasnet_100',\n",
              " 'ssl_resnet18',\n",
              " 'ssl_resnet50',\n",
              " 'ssl_resnext50_32x4d',\n",
              " 'ssl_resnext101_32x4d',\n",
              " 'ssl_resnext101_32x8d',\n",
              " 'ssl_resnext101_32x16d',\n",
              " 'swin_base_patch4_window7_224',\n",
              " 'swin_base_patch4_window7_224_in22k',\n",
              " 'swin_base_patch4_window12_384',\n",
              " 'swin_base_patch4_window12_384_in22k',\n",
              " 'swin_large_patch4_window7_224',\n",
              " 'swin_large_patch4_window7_224_in22k',\n",
              " 'swin_large_patch4_window12_384',\n",
              " 'swin_large_patch4_window12_384_in22k',\n",
              " 'swin_s3_base_224',\n",
              " 'swin_s3_small_224',\n",
              " 'swin_s3_tiny_224',\n",
              " 'swin_small_patch4_window7_224',\n",
              " 'swin_tiny_patch4_window7_224',\n",
              " 'swinv2_base_window8_256',\n",
              " 'swinv2_base_window12_192_22k',\n",
              " 'swinv2_base_window12to16_192to256_22kft1k',\n",
              " 'swinv2_base_window12to24_192to384_22kft1k',\n",
              " 'swinv2_base_window16_256',\n",
              " 'swinv2_cr_base_224',\n",
              " 'swinv2_cr_base_384',\n",
              " 'swinv2_cr_base_ns_224',\n",
              " 'swinv2_cr_giant_224',\n",
              " 'swinv2_cr_giant_384',\n",
              " 'swinv2_cr_huge_224',\n",
              " 'swinv2_cr_huge_384',\n",
              " 'swinv2_cr_large_224',\n",
              " 'swinv2_cr_large_384',\n",
              " 'swinv2_cr_small_224',\n",
              " 'swinv2_cr_small_384',\n",
              " 'swinv2_cr_small_ns_224',\n",
              " 'swinv2_cr_tiny_224',\n",
              " 'swinv2_cr_tiny_384',\n",
              " 'swinv2_cr_tiny_ns_224',\n",
              " 'swinv2_large_window12_192_22k',\n",
              " 'swinv2_large_window12to16_192to256_22kft1k',\n",
              " 'swinv2_large_window12to24_192to384_22kft1k',\n",
              " 'swinv2_small_window8_256',\n",
              " 'swinv2_small_window16_256',\n",
              " 'swinv2_tiny_window8_256',\n",
              " 'swinv2_tiny_window16_256',\n",
              " 'swsl_resnet18',\n",
              " 'swsl_resnet50',\n",
              " 'swsl_resnext50_32x4d',\n",
              " 'swsl_resnext101_32x4d',\n",
              " 'swsl_resnext101_32x8d',\n",
              " 'swsl_resnext101_32x16d',\n",
              " 'tf_efficientnet_b0',\n",
              " 'tf_efficientnet_b0_ap',\n",
              " 'tf_efficientnet_b0_ns',\n",
              " 'tf_efficientnet_b1',\n",
              " 'tf_efficientnet_b1_ap',\n",
              " 'tf_efficientnet_b1_ns',\n",
              " 'tf_efficientnet_b2',\n",
              " 'tf_efficientnet_b2_ap',\n",
              " 'tf_efficientnet_b2_ns',\n",
              " 'tf_efficientnet_b3',\n",
              " 'tf_efficientnet_b3_ap',\n",
              " 'tf_efficientnet_b3_ns',\n",
              " 'tf_efficientnet_b4',\n",
              " 'tf_efficientnet_b4_ap',\n",
              " 'tf_efficientnet_b4_ns',\n",
              " 'tf_efficientnet_b5',\n",
              " 'tf_efficientnet_b5_ap',\n",
              " 'tf_efficientnet_b5_ns',\n",
              " 'tf_efficientnet_b6',\n",
              " 'tf_efficientnet_b6_ap',\n",
              " 'tf_efficientnet_b6_ns',\n",
              " 'tf_efficientnet_b7',\n",
              " 'tf_efficientnet_b7_ap',\n",
              " 'tf_efficientnet_b7_ns',\n",
              " 'tf_efficientnet_b8',\n",
              " 'tf_efficientnet_b8_ap',\n",
              " 'tf_efficientnet_cc_b0_4e',\n",
              " 'tf_efficientnet_cc_b0_8e',\n",
              " 'tf_efficientnet_cc_b1_8e',\n",
              " 'tf_efficientnet_el',\n",
              " 'tf_efficientnet_em',\n",
              " 'tf_efficientnet_es',\n",
              " 'tf_efficientnet_l2_ns',\n",
              " 'tf_efficientnet_l2_ns_475',\n",
              " 'tf_efficientnet_lite0',\n",
              " 'tf_efficientnet_lite1',\n",
              " 'tf_efficientnet_lite2',\n",
              " 'tf_efficientnet_lite3',\n",
              " 'tf_efficientnet_lite4',\n",
              " 'tf_efficientnetv2_b0',\n",
              " 'tf_efficientnetv2_b1',\n",
              " 'tf_efficientnetv2_b2',\n",
              " 'tf_efficientnetv2_b3',\n",
              " 'tf_efficientnetv2_l',\n",
              " 'tf_efficientnetv2_l_in21ft1k',\n",
              " 'tf_efficientnetv2_l_in21k',\n",
              " 'tf_efficientnetv2_m',\n",
              " 'tf_efficientnetv2_m_in21ft1k',\n",
              " 'tf_efficientnetv2_m_in21k',\n",
              " 'tf_efficientnetv2_s',\n",
              " 'tf_efficientnetv2_s_in21ft1k',\n",
              " 'tf_efficientnetv2_s_in21k',\n",
              " 'tf_efficientnetv2_xl_in21ft1k',\n",
              " 'tf_efficientnetv2_xl_in21k',\n",
              " 'tf_inception_v3',\n",
              " 'tf_mixnet_l',\n",
              " 'tf_mixnet_m',\n",
              " 'tf_mixnet_s',\n",
              " 'tf_mobilenetv3_large_075',\n",
              " 'tf_mobilenetv3_large_100',\n",
              " 'tf_mobilenetv3_large_minimal_100',\n",
              " 'tf_mobilenetv3_small_075',\n",
              " 'tf_mobilenetv3_small_100',\n",
              " 'tf_mobilenetv3_small_minimal_100',\n",
              " 'tinynet_a',\n",
              " 'tinynet_b',\n",
              " 'tinynet_c',\n",
              " 'tinynet_d',\n",
              " 'tinynet_e',\n",
              " 'tnt_b_patch16_224',\n",
              " 'tnt_s_patch16_224',\n",
              " 'tresnet_l',\n",
              " 'tresnet_l_448',\n",
              " 'tresnet_m',\n",
              " 'tresnet_m_448',\n",
              " 'tresnet_m_miil_in21k',\n",
              " 'tresnet_v2_l',\n",
              " 'tresnet_xl',\n",
              " 'tresnet_xl_448',\n",
              " 'tv_densenet121',\n",
              " 'tv_resnet34',\n",
              " 'tv_resnet50',\n",
              " 'tv_resnet101',\n",
              " 'tv_resnet152',\n",
              " 'tv_resnext50_32x4d',\n",
              " 'twins_pcpvt_base',\n",
              " 'twins_pcpvt_large',\n",
              " 'twins_pcpvt_small',\n",
              " 'twins_svt_base',\n",
              " 'twins_svt_large',\n",
              " 'twins_svt_small',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'visformer_small',\n",
              " 'visformer_tiny',\n",
              " 'vit_base_patch8_224',\n",
              " 'vit_base_patch8_224_dino',\n",
              " 'vit_base_patch8_224_in21k',\n",
              " 'vit_base_patch16_18x2_224',\n",
              " 'vit_base_patch16_224',\n",
              " 'vit_base_patch16_224_dino',\n",
              " 'vit_base_patch16_224_in21k',\n",
              " 'vit_base_patch16_224_miil',\n",
              " 'vit_base_patch16_224_miil_in21k',\n",
              " 'vit_base_patch16_224_sam',\n",
              " 'vit_base_patch16_384',\n",
              " 'vit_base_patch16_plus_240',\n",
              " 'vit_base_patch16_rpn_224',\n",
              " 'vit_base_patch32_224',\n",
              " 'vit_base_patch32_224_clip_laion2b',\n",
              " 'vit_base_patch32_224_in21k',\n",
              " 'vit_base_patch32_224_sam',\n",
              " 'vit_base_patch32_384',\n",
              " 'vit_base_patch32_plus_256',\n",
              " 'vit_base_r26_s32_224',\n",
              " 'vit_base_r50_s16_224',\n",
              " 'vit_base_r50_s16_224_in21k',\n",
              " 'vit_base_r50_s16_384',\n",
              " 'vit_base_resnet26d_224',\n",
              " 'vit_base_resnet50_224_in21k',\n",
              " 'vit_base_resnet50_384',\n",
              " 'vit_base_resnet50d_224',\n",
              " 'vit_giant_patch14_224',\n",
              " 'vit_giant_patch14_224_clip_laion2b',\n",
              " 'vit_gigantic_patch14_224',\n",
              " 'vit_huge_patch14_224',\n",
              " 'vit_huge_patch14_224_clip_laion2b',\n",
              " 'vit_huge_patch14_224_in21k',\n",
              " 'vit_large_patch14_224',\n",
              " 'vit_large_patch14_224_clip_laion2b',\n",
              " 'vit_large_patch16_224',\n",
              " 'vit_large_patch16_224_in21k',\n",
              " 'vit_large_patch16_384',\n",
              " 'vit_large_patch32_224',\n",
              " 'vit_large_patch32_224_in21k',\n",
              " 'vit_large_patch32_384',\n",
              " 'vit_large_r50_s32_224',\n",
              " 'vit_large_r50_s32_224_in21k',\n",
              " 'vit_large_r50_s32_384',\n",
              " 'vit_relpos_base_patch16_224',\n",
              " 'vit_relpos_base_patch16_cls_224',\n",
              " 'vit_relpos_base_patch16_clsgap_224',\n",
              " 'vit_relpos_base_patch16_plus_240',\n",
              " 'vit_relpos_base_patch16_rpn_224',\n",
              " 'vit_relpos_base_patch32_plus_rpn_256',\n",
              " 'vit_relpos_medium_patch16_224',\n",
              " 'vit_relpos_medium_patch16_cls_224',\n",
              " 'vit_relpos_medium_patch16_rpn_224',\n",
              " 'vit_relpos_small_patch16_224',\n",
              " 'vit_relpos_small_patch16_rpn_224',\n",
              " 'vit_small_patch8_224_dino',\n",
              " 'vit_small_patch16_18x2_224',\n",
              " 'vit_small_patch16_36x1_224',\n",
              " 'vit_small_patch16_224',\n",
              " 'vit_small_patch16_224_dino',\n",
              " 'vit_small_patch16_224_in21k',\n",
              " 'vit_small_patch16_384',\n",
              " 'vit_small_patch32_224',\n",
              " 'vit_small_patch32_224_in21k',\n",
              " 'vit_small_patch32_384',\n",
              " 'vit_small_r26_s32_224',\n",
              " 'vit_small_r26_s32_224_in21k',\n",
              " 'vit_small_r26_s32_384',\n",
              " 'vit_small_resnet26d_224',\n",
              " 'vit_small_resnet50d_s16_224',\n",
              " 'vit_srelpos_medium_patch16_224',\n",
              " 'vit_srelpos_small_patch16_224',\n",
              " 'vit_tiny_patch16_224',\n",
              " 'vit_tiny_patch16_224_in21k',\n",
              " 'vit_tiny_patch16_384',\n",
              " 'vit_tiny_r_s16_p8_224',\n",
              " 'vit_tiny_r_s16_p8_224_in21k',\n",
              " 'vit_tiny_r_s16_p8_384',\n",
              " 'volo_d1_224',\n",
              " 'volo_d1_384',\n",
              " 'volo_d2_224',\n",
              " 'volo_d2_384',\n",
              " 'volo_d3_224',\n",
              " 'volo_d3_448',\n",
              " 'volo_d4_224',\n",
              " 'volo_d4_448',\n",
              " 'volo_d5_224',\n",
              " 'volo_d5_448',\n",
              " 'volo_d5_512',\n",
              " 'vovnet39a',\n",
              " 'vovnet57a',\n",
              " 'wide_resnet50_2',\n",
              " 'wide_resnet101_2',\n",
              " 'xception',\n",
              " 'xception41',\n",
              " 'xception41p',\n",
              " 'xception65',\n",
              " 'xception65p',\n",
              " 'xception71',\n",
              " 'xcit_large_24_p8_224',\n",
              " 'xcit_large_24_p8_224_dist',\n",
              " 'xcit_large_24_p8_384_dist',\n",
              " 'xcit_large_24_p16_224',\n",
              " 'xcit_large_24_p16_224_dist',\n",
              " 'xcit_large_24_p16_384_dist',\n",
              " 'xcit_medium_24_p8_224',\n",
              " 'xcit_medium_24_p8_224_dist',\n",
              " 'xcit_medium_24_p8_384_dist',\n",
              " 'xcit_medium_24_p16_224',\n",
              " 'xcit_medium_24_p16_224_dist',\n",
              " 'xcit_medium_24_p16_384_dist',\n",
              " 'xcit_nano_12_p8_224',\n",
              " 'xcit_nano_12_p8_224_dist',\n",
              " 'xcit_nano_12_p8_384_dist',\n",
              " 'xcit_nano_12_p16_224',\n",
              " 'xcit_nano_12_p16_224_dist',\n",
              " 'xcit_nano_12_p16_384_dist',\n",
              " 'xcit_small_12_p8_224',\n",
              " 'xcit_small_12_p8_224_dist',\n",
              " 'xcit_small_12_p8_384_dist',\n",
              " 'xcit_small_12_p16_224',\n",
              " 'xcit_small_12_p16_224_dist',\n",
              " 'xcit_small_12_p16_384_dist',\n",
              " 'xcit_small_24_p8_224',\n",
              " 'xcit_small_24_p8_224_dist',\n",
              " 'xcit_small_24_p8_384_dist',\n",
              " 'xcit_small_24_p16_224',\n",
              " 'xcit_small_24_p16_224_dist',\n",
              " 'xcit_small_24_p16_384_dist',\n",
              " 'xcit_tiny_12_p8_224',\n",
              " 'xcit_tiny_12_p8_224_dist',\n",
              " 'xcit_tiny_12_p8_384_dist',\n",
              " 'xcit_tiny_12_p16_224',\n",
              " 'xcit_tiny_12_p16_224_dist',\n",
              " 'xcit_tiny_12_p16_384_dist',\n",
              " 'xcit_tiny_24_p8_224',\n",
              " 'xcit_tiny_24_p8_224_dist',\n",
              " 'xcit_tiny_24_p8_384_dist',\n",
              " 'xcit_tiny_24_p16_224',\n",
              " 'xcit_tiny_24_p16_224_dist',\n",
              " 'xcit_tiny_24_p16_384_dist']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = timm.create_model('mobilenetv3_small_050', pretrained=False, num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "total=0 \n",
        "correct = 0"
      ],
      "metadata": {
        "id": "Os2IBshCP2bO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs= net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 750 ==749:\n",
        "      print(\"Epoch: {},Batch : {}, Loss:{}\".format(epoch+1, i+1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    val_loss = 0.0\n",
        "    for k, data1 in enumerate(vaild_loader, 0):\n",
        "      val_inputs, val_label = data1[0].to(device), data1[1].to(device)\n",
        "      val_output = net(val_inputs)\n",
        "      v_loss = criterion(val_output, val_label)\n",
        "      val_loss += v_loss\n",
        "  print(\"validation loss : {}\".format(val_loss))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs= net(images)\n",
        "      _, predicted = torch.max(outputs.data,1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(\"testset Accuracy  : {}\".format(100* correct/total))\n",
        "  total=0\n",
        "  correct=0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q8IufYT0P4Zx",
        "outputId": "25a5598f-aab7-4f2a-b2e1-bfa77a230c41"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1,Batch : 750, Loss:0.9304577376842499\n",
            "Epoch: 1,Batch : 1500, Loss:0.8394011863470078\n",
            "Epoch: 1,Batch : 2250, Loss:0.8217458894848824\n",
            "Epoch: 1,Batch : 3000, Loss:0.8037130026221275\n",
            "validation loss : 336.3591003417969\n",
            "testset Accuracy  : 12.05\n",
            "Epoch: 2,Batch : 750, Loss:0.7850187532305718\n",
            "Epoch: 2,Batch : 1500, Loss:0.7775745748877525\n",
            "Epoch: 2,Batch : 2250, Loss:0.7824703488945961\n",
            "Epoch: 2,Batch : 3000, Loss:0.7719941746592521\n",
            "validation loss : 328.20172119140625\n",
            "testset Accuracy  : 10.8\n",
            "Epoch: 3,Batch : 750, Loss:0.7696706448197365\n",
            "Epoch: 3,Batch : 1500, Loss:0.7663005501031875\n",
            "Epoch: 3,Batch : 2250, Loss:0.7533973727822304\n",
            "Epoch: 3,Batch : 3000, Loss:0.7460049788951874\n",
            "validation loss : 312.0575866699219\n",
            "testset Accuracy  : 11.2\n",
            "Epoch: 4,Batch : 750, Loss:0.7392868000268936\n",
            "Epoch: 4,Batch : 1500, Loss:0.7387275158166885\n",
            "Epoch: 4,Batch : 2250, Loss:0.7506667543053627\n",
            "Epoch: 4,Batch : 3000, Loss:0.7351224486231804\n",
            "validation loss : 301.2264709472656\n",
            "testset Accuracy  : 10.45\n",
            "Epoch: 5,Batch : 750, Loss:0.7307457922697067\n",
            "Epoch: 5,Batch : 1500, Loss:0.7309217815399169\n",
            "Epoch: 5,Batch : 2250, Loss:0.7326993466615677\n",
            "Epoch: 5,Batch : 3000, Loss:0.7548623664975166\n",
            "validation loss : 323.6523742675781\n",
            "testset Accuracy  : 11.3\n",
            "Epoch: 6,Batch : 750, Loss:0.7501225215792656\n",
            "Epoch: 6,Batch : 1500, Loss:0.7271723215579986\n",
            "Epoch: 6,Batch : 2250, Loss:0.7158988381624222\n",
            "Epoch: 6,Batch : 3000, Loss:0.7344113655090332\n",
            "validation loss : 300.8890686035156\n",
            "testset Accuracy  : 10.45\n",
            "Epoch: 7,Batch : 750, Loss:0.7240031551122665\n",
            "Epoch: 7,Batch : 1500, Loss:0.7034881093502044\n",
            "Epoch: 7,Batch : 2250, Loss:0.7016719248890877\n",
            "Epoch: 7,Batch : 3000, Loss:0.7576096642613411\n",
            "validation loss : 312.8197326660156\n",
            "testset Accuracy  : 11.95\n",
            "Epoch: 8,Batch : 750, Loss:0.7313048092722892\n",
            "Epoch: 8,Batch : 1500, Loss:0.7090214077830315\n",
            "Epoch: 8,Batch : 2250, Loss:0.7131088528633117\n",
            "Epoch: 8,Batch : 3000, Loss:0.7018704573512078\n",
            "validation loss : 285.4637756347656\n",
            "testset Accuracy  : 11.25\n",
            "Epoch: 9,Batch : 750, Loss:0.6950407984256745\n",
            "Epoch: 9,Batch : 1500, Loss:0.6885702175498009\n",
            "Epoch: 9,Batch : 2250, Loss:0.6897073172330856\n",
            "Epoch: 9,Batch : 3000, Loss:0.7018225696086884\n",
            "validation loss : 283.5631103515625\n",
            "testset Accuracy  : 11.45\n",
            "Epoch: 10,Batch : 750, Loss:0.6857613053321838\n",
            "Epoch: 10,Batch : 1500, Loss:0.6761896266937256\n",
            "Epoch: 10,Batch : 2250, Loss:0.6694919119477272\n",
            "Epoch: 10,Batch : 3000, Loss:0.6671803450584411\n",
            "validation loss : 273.9600524902344\n",
            "testset Accuracy  : 11.15\n",
            "Epoch: 11,Batch : 750, Loss:0.664373829126358\n",
            "Epoch: 11,Batch : 1500, Loss:0.6663912858963013\n",
            "Epoch: 11,Batch : 2250, Loss:0.6558346430659294\n",
            "Epoch: 11,Batch : 3000, Loss:0.6604830601811409\n",
            "validation loss : 270.83056640625\n",
            "testset Accuracy  : 12.4\n",
            "Epoch: 12,Batch : 750, Loss:0.6539477536082268\n",
            "Epoch: 12,Batch : 1500, Loss:0.6467004823684692\n",
            "Epoch: 12,Batch : 2250, Loss:0.6539348922371865\n",
            "Epoch: 12,Batch : 3000, Loss:0.6443987511396408\n",
            "validation loss : 261.3894958496094\n",
            "testset Accuracy  : 12.05\n",
            "Epoch: 13,Batch : 750, Loss:0.6487588765025138\n",
            "Epoch: 13,Batch : 1500, Loss:0.6545655564069748\n",
            "Epoch: 13,Batch : 2250, Loss:0.6350407698750495\n",
            "Epoch: 13,Batch : 3000, Loss:0.6385261015892029\n",
            "validation loss : 261.6051025390625\n",
            "testset Accuracy  : 12.3\n",
            "Epoch: 14,Batch : 750, Loss:0.6479716963768005\n",
            "Epoch: 14,Batch : 1500, Loss:0.6374412636160851\n",
            "Epoch: 14,Batch : 2250, Loss:0.6391208954453468\n",
            "Epoch: 14,Batch : 3000, Loss:0.6244642255306244\n",
            "validation loss : 255.8519744873047\n",
            "testset Accuracy  : 11.8\n",
            "Epoch: 15,Batch : 750, Loss:0.6223119292259216\n",
            "Epoch: 15,Batch : 1500, Loss:0.6313707450628281\n",
            "Epoch: 15,Batch : 2250, Loss:0.6229167369008064\n",
            "Epoch: 15,Batch : 3000, Loss:0.6238538082242012\n",
            "validation loss : 254.51162719726562\n",
            "testset Accuracy  : 12.85\n",
            "Epoch: 16,Batch : 750, Loss:0.6206346355974675\n",
            "Epoch: 16,Batch : 1500, Loss:0.6280080279707909\n",
            "Epoch: 16,Batch : 2250, Loss:0.6174051318466663\n",
            "Epoch: 16,Batch : 3000, Loss:0.6181864967942238\n",
            "validation loss : 250.26341247558594\n",
            "testset Accuracy  : 13.15\n",
            "Epoch: 17,Batch : 750, Loss:0.6138571978807449\n",
            "Epoch: 17,Batch : 1500, Loss:0.6061805927157402\n",
            "Epoch: 17,Batch : 2250, Loss:0.6065978317856788\n",
            "Epoch: 17,Batch : 3000, Loss:0.6111317891180515\n",
            "validation loss : 247.10324096679688\n",
            "testset Accuracy  : 12.55\n",
            "Epoch: 18,Batch : 750, Loss:0.6079477114081383\n",
            "Epoch: 18,Batch : 1500, Loss:0.5982099895477295\n",
            "Epoch: 18,Batch : 2250, Loss:0.6103591132760048\n",
            "Epoch: 18,Batch : 3000, Loss:0.6060378009378911\n",
            "validation loss : 245.92591857910156\n",
            "testset Accuracy  : 13.05\n",
            "Epoch: 19,Batch : 750, Loss:0.6026075940132141\n",
            "Epoch: 19,Batch : 1500, Loss:0.5971932701170445\n",
            "Epoch: 19,Batch : 2250, Loss:0.6041048212051392\n",
            "Epoch: 19,Batch : 3000, Loss:0.5930859622061253\n",
            "validation loss : 241.2666778564453\n",
            "testset Accuracy  : 12.95\n",
            "Epoch: 20,Batch : 750, Loss:0.5945064379572869\n",
            "Epoch: 20,Batch : 1500, Loss:0.5844478831589222\n",
            "Epoch: 20,Batch : 2250, Loss:0.5873662709295749\n",
            "Epoch: 20,Batch : 3000, Loss:0.5875929708480835\n",
            "validation loss : 239.77781677246094\n",
            "testset Accuracy  : 13.45\n",
            "Epoch: 21,Batch : 750, Loss:0.5835456687808037\n",
            "Epoch: 21,Batch : 1500, Loss:0.5849672732651233\n",
            "Epoch: 21,Batch : 2250, Loss:0.5885657420754433\n",
            "Epoch: 21,Batch : 3000, Loss:0.5912017296254635\n",
            "validation loss : 240.5474090576172\n",
            "testset Accuracy  : 12.8\n",
            "Epoch: 22,Batch : 750, Loss:0.5821059084534645\n",
            "Epoch: 22,Batch : 1500, Loss:0.5860733734071255\n",
            "Epoch: 22,Batch : 2250, Loss:0.5803632653951645\n",
            "Epoch: 22,Batch : 3000, Loss:0.5795202727615834\n",
            "validation loss : 236.02017211914062\n",
            "testset Accuracy  : 12.7\n",
            "Epoch: 23,Batch : 750, Loss:0.5769776033461094\n",
            "Epoch: 23,Batch : 1500, Loss:0.5751924659013748\n",
            "Epoch: 23,Batch : 2250, Loss:0.580868471056223\n",
            "Epoch: 23,Batch : 3000, Loss:0.5830179999172688\n",
            "validation loss : 235.91690063476562\n",
            "testset Accuracy  : 13.65\n",
            "Epoch: 24,Batch : 750, Loss:0.5750623072683811\n",
            "Epoch: 24,Batch : 1500, Loss:0.582278212249279\n",
            "Epoch: 24,Batch : 2250, Loss:0.5732312918901443\n",
            "Epoch: 24,Batch : 3000, Loss:0.5717068420648574\n",
            "validation loss : 233.9056396484375\n",
            "testset Accuracy  : 13.95\n",
            "Epoch: 25,Batch : 750, Loss:0.5755095159709454\n",
            "Epoch: 25,Batch : 1500, Loss:0.5690257151424885\n",
            "Epoch: 25,Batch : 2250, Loss:0.5670122137069702\n",
            "Epoch: 25,Batch : 3000, Loss:0.5627458088994026\n",
            "validation loss : 232.7950439453125\n",
            "testset Accuracy  : 12.95\n",
            "Epoch: 26,Batch : 750, Loss:0.5594939455389977\n",
            "Epoch: 26,Batch : 1500, Loss:0.5577409625649452\n",
            "Epoch: 26,Batch : 2250, Loss:0.5612460393607617\n",
            "Epoch: 26,Batch : 3000, Loss:0.5551079914569855\n",
            "validation loss : 249.68727111816406\n",
            "testset Accuracy  : 13.25\n",
            "Epoch: 27,Batch : 750, Loss:0.5518758261203766\n",
            "Epoch: 27,Batch : 1500, Loss:0.5493803669214249\n",
            "Epoch: 27,Batch : 2250, Loss:0.5457298836112022\n",
            "Epoch: 27,Batch : 3000, Loss:0.5483525726497174\n",
            "validation loss : 220.96151733398438\n",
            "testset Accuracy  : 14.35\n",
            "Epoch: 28,Batch : 750, Loss:0.5441165219545364\n",
            "Epoch: 28,Batch : 1500, Loss:0.5444146257340908\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-aef6fe1c5fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/mobilenetv3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/mobilenetv3.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_pw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/layers/norm_act.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2439\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m     )\n\u001b[1;32m   2441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pretrained 넣기\n"
      ],
      "metadata": {
        "id": "KqDJoCltxkKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/share/trained_model/cifar_effnetv2_s.pth'\n",
        "\n"
      ],
      "metadata": {
        "id": "S0fKwJo7P4iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "9VJnnqHYI-Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane','automobile','bird','cat','deer',\n",
        "           'dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "47ZGkY0NX5if"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    c= (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label= labels[i]\n",
        "      class_correct[label]+= c[i].item()\n",
        "      class_total[label]+= 1\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Accuracy of {} : {} %\".format(classes[i],100* class_correct[i]/class_total[i]))"
      ],
      "metadata": {
        "id": "QOaHVH52X5kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3220fbb2-c06a-4290-8397-834383c4cbfa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of plane : 25.0 %\n",
            "Accuracy of automobile : 25.0 %\n",
            "Accuracy of bird : 8.333333333333334 %\n",
            "Accuracy of cat : 16.666666666666668 %\n",
            "Accuracy of deer : 16.666666666666668 %\n",
            "Accuracy of dog : 8.333333333333334 %\n",
            "Accuracy of frog : 25.0 %\n",
            "Accuracy of horse : 0.0 %\n",
            "Accuracy of ship : 31.25 %\n",
            "Accuracy of truck : 16.666666666666668 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLanzQjcfLzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"trainset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44HdYYfb5Eja",
        "outputId": "11562c9b-18aa-4280-ac6f-faf45556b258"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainset Accuracy  : 49.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in vaild_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"vaildset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "id": "xKUJChxdX5Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a66152b-b3e8-438c-866d-87404585a526"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vaildset Accuracy  : 49.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"testset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "id": "O8NlBkmgX5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081f17a2-3a89-436b-c10a-b8cc7c4d17c1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset Accuracy  : 14.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader.dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4phrVKIWPxzj",
        "outputId": "626ea7f4-cb06-456f-8911-6a46033e9efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 2000\n",
              "    Root location: /content/drive/MyDrive/share/images/Statistical_Deep_Image\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               RandomGrayscale(p=1)\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}