{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import math\n",
        "import os"
      ],
      "metadata": {
        "id": "RJqq2BV4Uhk2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    seed = 42\n",
        "    device = \"cuda:0\"    \n",
        "        \n",
        "    lr = 1e-3\n",
        "    epochs = 25\n",
        "    batch_size = 32\n",
        "    num_workers = 4\n",
        "    train_5_folds = True\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "seed_everything(config.seed)"
      ],
      "metadata": {
        "id": "3vyQQ0rYqwp9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnZf8_DlJRxC",
        "outputId": "a79b0b84-6db0-4bec-b68c-916a46ca4848"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform  = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
      ],
      "metadata": {
        "id": "8qw6bRoGLEqk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='/data',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform)\n",
        "\n",
        "vaildset = torchvision.datasets.CIFAR10(root='/data',\n",
        "                                        train=False,\n",
        "                                        download=True,\n",
        "                                        transform=transform)"
      ],
      "metadata": {
        "id": "X3YUvobnJimS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df03764-5c04-4c8f-8028-1c2a0de13124"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.ImageFolder(root = \"/content/drive/MyDrive/share/images/Statistical_Deep_Image\",\n",
        "                                           transform = transform)"
      ],
      "metadata": {
        "id": "Zd8-9_oDSQK_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(trainset,\n",
        "                          batch_size = 32,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "vaild_loader = DataLoader(vaildset,\n",
        "                          batch_size = 64,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "\n",
        "test_loader = DataLoader(testset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)"
      ],
      "metadata": {
        "id": "JRxWLJjnKUIt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 넣기 "
      ],
      "metadata": {
        "id": "1hTgHG91xbSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "__all__ = ['effnetv2_s', 'effnetv2_m', 'effnetv2_l', 'effnetv2_xl']\n",
        "\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "# SiLU (Swish) activation function\n",
        "if hasattr(nn, 'SiLU'):\n",
        "    SiLU = nn.SiLU\n",
        "else:\n",
        "    # For compatibility with old PyTorch versions\n",
        "    class SiLU(nn.Module):\n",
        "        def forward(self, x):\n",
        "            return x * torch.sigmoid(x)\n",
        "\n",
        " \n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, inp, oup, reduction=4):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "                nn.Linear(oup, _make_divisible(inp // reduction, 8)),\n",
        "                SiLU(),\n",
        "                nn.Linear(_make_divisible(inp // reduction, 8), oup),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "def conv_3x3_bn(inp, oup, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        SiLU()\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_1x1_bn(inp, oup):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        SiLU()\n",
        "    )\n",
        "\n",
        "\n",
        "class MBConv(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio, use_se):\n",
        "        super(MBConv, self).__init__()\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = round(inp * expand_ratio)\n",
        "        self.identity = stride == 1 and inp == oup\n",
        "        if use_se:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                SiLU(),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                SiLU(),\n",
        "                SELayer(inp, hidden_dim),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # fused\n",
        "                nn.Conv2d(inp, hidden_dim, 3, stride, 1, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                SiLU(),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.identity:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class EffNetV2(nn.Module):\n",
        "    def __init__(self, cfgs, num_classes=1000, width_mult=1.):\n",
        "        super(EffNetV2, self).__init__()\n",
        "        self.cfgs = cfgs\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(24 * width_mult, 8)\n",
        "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
        "        # building inverted residual blocks\n",
        "        block = MBConv\n",
        "        for t, c, n, s, use_se in self.cfgs:\n",
        "            output_channel = _make_divisible(c * width_mult, 8)\n",
        "            for i in range(n):\n",
        "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t, use_se))\n",
        "                input_channel = output_channel\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        # building last several layers\n",
        "        output_channel = _make_divisible(1792 * width_mult, 8) if width_mult > 1.0 else 1792\n",
        "        self.conv = conv_1x1_bn(input_channel, output_channel)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Linear(output_channel, num_classes)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.001)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "def effnetv2_s(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a EfficientNetV2-S model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # t, c, n, s, SE\n",
        "        [1,  24,  2, 1, 0],\n",
        "        [4,  48,  4, 2, 0],\n",
        "        [4,  64,  4, 2, 0],\n",
        "        [4, 128,  6, 2, 1],\n",
        "        [6, 160,  9, 1, 1],\n",
        "        [6, 256, 15, 2, 1],\n",
        "    ]\n",
        "    return EffNetV2(cfgs, **kwargs)\n",
        "\n",
        "\n",
        "def effnetv2_m(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a EfficientNetV2-M model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # t, c, n, s, SE\n",
        "        [1,  24,  3, 1, 0],\n",
        "        [4,  48,  5, 2, 0],\n",
        "        [4,  80,  5, 2, 0],\n",
        "        [4, 160,  7, 2, 1],\n",
        "        [6, 176, 14, 1, 1],\n",
        "        [6, 304, 18, 2, 1],\n",
        "        [6, 512,  5, 1, 1],\n",
        "    ]\n",
        "    return EffNetV2(cfgs, **kwargs)\n",
        "\n",
        "\n",
        "def effnetv2_l(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a EfficientNetV2-L model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # t, c, n, s, SE\n",
        "        [1,  32,  4, 1, 0],\n",
        "        [4,  64,  7, 2, 0],\n",
        "        [4,  96,  7, 2, 0],\n",
        "        [4, 192, 10, 2, 1],\n",
        "        [6, 224, 19, 1, 1],\n",
        "        [6, 384, 25, 2, 1],\n",
        "        [6, 640,  7, 1, 1],\n",
        "    ]\n",
        "    return EffNetV2(cfgs, **kwargs)\n",
        "\n",
        "\n",
        "def effnetv2_xl(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a EfficientNetV2-XL model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # t, c, n, s, SE\n",
        "        [1,  32,  4, 1, 0],\n",
        "        [4,  64,  8, 2, 0],\n",
        "        [4,  96,  8, 2, 0],\n",
        "        [4, 192, 16, 2, 1],\n",
        "        [6, 256, 24, 1, 1],\n",
        "        [6, 512, 32, 2, 1],\n",
        "        [6, 640,  8, 1, 1],\n",
        "    ]\n",
        "    return EffNetV2(cfgs, **kwargs)"
      ],
      "metadata": {
        "id": "NkV4EfO4VplZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = effnetv2_s(num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "total=0 \n",
        "correct = 0"
      ],
      "metadata": {
        "id": "Os2IBshCP2bO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs= net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 750 ==749:\n",
        "      print(\"Epoch: {},Batch : {}, Loss:{}\".format(epoch+1, i+1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    val_loss = 0.0\n",
        "    for k, data1 in enumerate(vaild_loader, 0):\n",
        "      val_inputs, val_label = data1[0].to(device), data1[1].to(device)\n",
        "      val_output = net(val_inputs)\n",
        "      v_loss = criterion(val_output, val_label)\n",
        "      val_loss += v_loss\n",
        "  print(\"validation loss {}\".format(val_loss))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs= net(images)\n",
        "      _, predicted = torch.max(outputs.data,1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(100* correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8IufYT0P4Zx",
        "outputId": "73901d7a-ed65-4bba-927f-50acd4d0553c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1,Batch : 750, Loss:0.721489525437355\n",
            "Epoch: 1,Batch : 1500, Loss:0.606228125333786\n",
            "validation loss 233.7251739501953\n",
            "9.95\n",
            "Epoch: 2,Batch : 750, Loss:0.554118922740221\n",
            "Epoch: 2,Batch : 1500, Loss:0.527217505723238\n",
            "validation loss 206.9401092529297\n",
            "10.875\n",
            "Epoch: 3,Batch : 750, Loss:0.4791901473701\n",
            "Epoch: 3,Batch : 1500, Loss:0.4639678617119789\n",
            "validation loss 188.09512329101562\n",
            "10.933333333333334\n",
            "Epoch: 4,Batch : 750, Loss:0.4150309758782387\n",
            "Epoch: 4,Batch : 1500, Loss:0.41230468356609346\n",
            "validation loss 173.7301483154297\n",
            "11.3375\n",
            "Epoch: 5,Batch : 750, Loss:0.37128016367554667\n",
            "Epoch: 5,Batch : 1500, Loss:0.36802840772271156\n",
            "validation loss 168.88320922851562\n",
            "11.75\n",
            "Epoch: 6,Batch : 750, Loss:0.3213112418055534\n",
            "Epoch: 6,Batch : 1500, Loss:0.32855674348771574\n",
            "validation loss 158.78488159179688\n",
            "11.95\n",
            "Epoch: 7,Batch : 750, Loss:0.28047382731735704\n",
            "Epoch: 7,Batch : 1500, Loss:0.29619285540282725\n",
            "validation loss 159.69520568847656\n",
            "12.035714285714286\n",
            "Epoch: 8,Batch : 750, Loss:0.24576277811080216\n",
            "Epoch: 8,Batch : 1500, Loss:0.2629994369149208\n",
            "validation loss 155.09677124023438\n",
            "12.36875\n",
            "Epoch: 9,Batch : 750, Loss:0.21313983358442784\n",
            "Epoch: 9,Batch : 1500, Loss:0.22853312838077544\n",
            "validation loss 157.2925567626953\n",
            "12.533333333333333\n",
            "Epoch: 10,Batch : 750, Loss:0.18294566882401705\n",
            "Epoch: 10,Batch : 1500, Loss:0.20084692066907883\n",
            "validation loss 164.53538513183594\n",
            "12.73\n",
            "Epoch: 11,Batch : 750, Loss:0.16008446005359292\n",
            "Epoch: 11,Batch : 1500, Loss:0.17341555116325616\n",
            "validation loss 164.19972229003906\n",
            "12.922727272727272\n",
            "Epoch: 12,Batch : 750, Loss:0.1335875322110951\n",
            "Epoch: 12,Batch : 1500, Loss:0.15604946511983872\n",
            "validation loss 174.84962463378906\n",
            "13.0625\n",
            "Epoch: 13,Batch : 750, Loss:0.11583076737262309\n",
            "Epoch: 13,Batch : 1500, Loss:0.13294347574561835\n",
            "validation loss 178.66204833984375\n",
            "13.334615384615384\n",
            "Epoch: 14,Batch : 750, Loss:0.10019949416350574\n",
            "Epoch: 14,Batch : 1500, Loss:0.1198122237585485\n",
            "validation loss 185.87933349609375\n",
            "13.510714285714286\n",
            "Epoch: 15,Batch : 750, Loss:0.08166780719812959\n",
            "Epoch: 15,Batch : 1500, Loss:0.09789691113866866\n",
            "validation loss 199.84854125976562\n",
            "13.723333333333333\n",
            "Epoch: 16,Batch : 750, Loss:0.0730740175503306\n",
            "Epoch: 16,Batch : 1500, Loss:0.08953524269815534\n",
            "validation loss 200.0727996826172\n",
            "13.9125\n",
            "Epoch: 17,Batch : 750, Loss:0.06306384401023388\n",
            "Epoch: 17,Batch : 1500, Loss:0.07352186118718236\n",
            "validation loss 212.39620971679688\n",
            "14.08235294117647\n",
            "Epoch: 18,Batch : 750, Loss:0.05762853211443871\n",
            "Epoch: 18,Batch : 1500, Loss:0.06509119288949296\n",
            "validation loss 215.97259521484375\n",
            "14.238888888888889\n",
            "Epoch: 19,Batch : 750, Loss:0.04837496959650889\n",
            "Epoch: 19,Batch : 1500, Loss:0.05962217887351289\n",
            "validation loss 225.79745483398438\n",
            "14.394736842105264\n",
            "Epoch: 20,Batch : 750, Loss:0.04398480605322402\n",
            "Epoch: 20,Batch : 1500, Loss:0.0525525067592971\n",
            "validation loss 232.46902465820312\n",
            "14.5525\n",
            "Epoch: 21,Batch : 750, Loss:0.040068354477873075\n",
            "Epoch: 21,Batch : 1500, Loss:0.04662402117229067\n",
            "validation loss 234.66802978515625\n",
            "14.66904761904762\n",
            "Epoch: 22,Batch : 750, Loss:0.034458727983757854\n",
            "Epoch: 22,Batch : 1500, Loss:0.042019126956933175\n",
            "validation loss 239.29757690429688\n",
            "14.836363636363636\n",
            "Epoch: 23,Batch : 750, Loss:0.0340008053939091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pretrained 넣기\n"
      ],
      "metadata": {
        "id": "KqDJoCltxkKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/share/trained_model/cifar_effnetv2_s.pth'\n",
        "torch.save(net.state_dict(), PATH)\n"
      ],
      "metadata": {
        "id": "S0fKwJo7P4iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "47ZGkY0NX5if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    c= (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label= labels[i]\n",
        "      class_correct[label]+= c[i].item()\n",
        "      class_total[label]+= 1\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Accuracy of {} : {} %\".format(classes[i],100* class_correct[i]/class_total[i]))"
      ],
      "metadata": {
        "id": "QOaHVH52X5kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLanzQjcfLzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Hfizy9LCavz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}