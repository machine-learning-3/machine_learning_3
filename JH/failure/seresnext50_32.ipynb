{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import math\n",
        "import os"
      ],
      "metadata": {
        "id": "RJqq2BV4Uhk2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEAdwOMRiY2f",
        "outputId": "35f6bb3d-03ae-4efd-c9e1-35a828b19cfc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    seed = 42\n",
        "    device = \"cuda:0\"    \n",
        "        \n",
        "    lr = 1e-3\n",
        "    epochs = 25\n",
        "    batch_size = 32\n",
        "    num_workers = 4\n",
        "    train_5_folds = True\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "seed_everything(config.seed)"
      ],
      "metadata": {
        "id": "3vyQQ0rYqwp9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnZf8_DlJRxC",
        "outputId": "031d3695-93e1-49d8-f403-b8c4697b96e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "transform_validation = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "transform  = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n"
      ],
      "metadata": {
        "id": "8qw6bRoGLEqk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train)\n",
        "\n",
        "vaildset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=False,\n",
        "                                        download=True,\n",
        "                                        transform=transform_validation)"
      ],
      "metadata": {
        "id": "X3YUvobnJimS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b99fbd5-883e-474d-c8e8-db8c785b67ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.ImageFolder(root = \"/content/drive/MyDrive/share/images/Statistical_Deep_Image\",\n",
        "                                           transform = transform)"
      ],
      "metadata": {
        "id": "Zd8-9_oDSQK_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(trainset,\n",
        "                          batch_size = 32,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "vaild_loader = DataLoader(vaildset,\n",
        "                          batch_size = 64,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "\n",
        "test_loader = DataLoader(testset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)"
      ],
      "metadata": {
        "id": "JRxWLJjnKUIt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 넣기 "
      ],
      "metadata": {
        "id": "1hTgHG91xbSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "import timm\n",
        "\n",
        "\n",
        "timm.list_models()\n"
      ],
      "metadata": {
        "id": "NkV4EfO4VplZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48b08f2-6096-4b3c-f6e3-d8ab50fd4377"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 27.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 59.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->timm) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.10.1 timm-0.6.11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adv_inception_v3',\n",
              " 'bat_resnext26ts',\n",
              " 'beit_base_patch16_224',\n",
              " 'beit_base_patch16_224_in22k',\n",
              " 'beit_base_patch16_384',\n",
              " 'beit_large_patch16_224',\n",
              " 'beit_large_patch16_224_in22k',\n",
              " 'beit_large_patch16_384',\n",
              " 'beit_large_patch16_512',\n",
              " 'beitv2_base_patch16_224',\n",
              " 'beitv2_base_patch16_224_in22k',\n",
              " 'beitv2_large_patch16_224',\n",
              " 'beitv2_large_patch16_224_in22k',\n",
              " 'botnet26t_256',\n",
              " 'botnet50ts_256',\n",
              " 'cait_m36_384',\n",
              " 'cait_m48_448',\n",
              " 'cait_s24_224',\n",
              " 'cait_s24_384',\n",
              " 'cait_s36_384',\n",
              " 'cait_xs24_384',\n",
              " 'cait_xxs24_224',\n",
              " 'cait_xxs24_384',\n",
              " 'cait_xxs36_224',\n",
              " 'cait_xxs36_384',\n",
              " 'coat_lite_mini',\n",
              " 'coat_lite_small',\n",
              " 'coat_lite_tiny',\n",
              " 'coat_mini',\n",
              " 'coat_tiny',\n",
              " 'coatnet_0_224',\n",
              " 'coatnet_0_rw_224',\n",
              " 'coatnet_1_224',\n",
              " 'coatnet_1_rw_224',\n",
              " 'coatnet_2_224',\n",
              " 'coatnet_2_rw_224',\n",
              " 'coatnet_3_224',\n",
              " 'coatnet_3_rw_224',\n",
              " 'coatnet_4_224',\n",
              " 'coatnet_5_224',\n",
              " 'coatnet_bn_0_rw_224',\n",
              " 'coatnet_nano_cc_224',\n",
              " 'coatnet_nano_rw_224',\n",
              " 'coatnet_pico_rw_224',\n",
              " 'coatnet_rmlp_0_rw_224',\n",
              " 'coatnet_rmlp_1_rw_224',\n",
              " 'coatnet_rmlp_2_rw_224',\n",
              " 'coatnet_rmlp_3_rw_224',\n",
              " 'coatnet_rmlp_nano_rw_224',\n",
              " 'coatnext_nano_rw_224',\n",
              " 'convit_base',\n",
              " 'convit_small',\n",
              " 'convit_tiny',\n",
              " 'convmixer_768_32',\n",
              " 'convmixer_1024_20_ks9_p14',\n",
              " 'convmixer_1536_20',\n",
              " 'convnext_atto',\n",
              " 'convnext_atto_ols',\n",
              " 'convnext_base',\n",
              " 'convnext_base_384_in22ft1k',\n",
              " 'convnext_base_in22ft1k',\n",
              " 'convnext_base_in22k',\n",
              " 'convnext_femto',\n",
              " 'convnext_femto_ols',\n",
              " 'convnext_large',\n",
              " 'convnext_large_384_in22ft1k',\n",
              " 'convnext_large_in22ft1k',\n",
              " 'convnext_large_in22k',\n",
              " 'convnext_nano',\n",
              " 'convnext_nano_ols',\n",
              " 'convnext_pico',\n",
              " 'convnext_pico_ols',\n",
              " 'convnext_small',\n",
              " 'convnext_small_384_in22ft1k',\n",
              " 'convnext_small_in22ft1k',\n",
              " 'convnext_small_in22k',\n",
              " 'convnext_tiny',\n",
              " 'convnext_tiny_384_in22ft1k',\n",
              " 'convnext_tiny_hnf',\n",
              " 'convnext_tiny_in22ft1k',\n",
              " 'convnext_tiny_in22k',\n",
              " 'convnext_xlarge_384_in22ft1k',\n",
              " 'convnext_xlarge_in22ft1k',\n",
              " 'convnext_xlarge_in22k',\n",
              " 'crossvit_9_240',\n",
              " 'crossvit_9_dagger_240',\n",
              " 'crossvit_15_240',\n",
              " 'crossvit_15_dagger_240',\n",
              " 'crossvit_15_dagger_408',\n",
              " 'crossvit_18_240',\n",
              " 'crossvit_18_dagger_240',\n",
              " 'crossvit_18_dagger_408',\n",
              " 'crossvit_base_240',\n",
              " 'crossvit_small_240',\n",
              " 'crossvit_tiny_240',\n",
              " 'cs3darknet_focus_l',\n",
              " 'cs3darknet_focus_m',\n",
              " 'cs3darknet_focus_s',\n",
              " 'cs3darknet_focus_x',\n",
              " 'cs3darknet_l',\n",
              " 'cs3darknet_m',\n",
              " 'cs3darknet_s',\n",
              " 'cs3darknet_x',\n",
              " 'cs3edgenet_x',\n",
              " 'cs3se_edgenet_x',\n",
              " 'cs3sedarknet_l',\n",
              " 'cs3sedarknet_x',\n",
              " 'cs3sedarknet_xdw',\n",
              " 'cspdarknet53',\n",
              " 'cspresnet50',\n",
              " 'cspresnet50d',\n",
              " 'cspresnet50w',\n",
              " 'cspresnext50',\n",
              " 'darknet17',\n",
              " 'darknet21',\n",
              " 'darknet53',\n",
              " 'darknetaa53',\n",
              " 'deit3_base_patch16_224',\n",
              " 'deit3_base_patch16_224_in21ft1k',\n",
              " 'deit3_base_patch16_384',\n",
              " 'deit3_base_patch16_384_in21ft1k',\n",
              " 'deit3_huge_patch14_224',\n",
              " 'deit3_huge_patch14_224_in21ft1k',\n",
              " 'deit3_large_patch16_224',\n",
              " 'deit3_large_patch16_224_in21ft1k',\n",
              " 'deit3_large_patch16_384',\n",
              " 'deit3_large_patch16_384_in21ft1k',\n",
              " 'deit3_medium_patch16_224',\n",
              " 'deit3_medium_patch16_224_in21ft1k',\n",
              " 'deit3_small_patch16_224',\n",
              " 'deit3_small_patch16_224_in21ft1k',\n",
              " 'deit3_small_patch16_384',\n",
              " 'deit3_small_patch16_384_in21ft1k',\n",
              " 'deit_base_distilled_patch16_224',\n",
              " 'deit_base_distilled_patch16_384',\n",
              " 'deit_base_patch16_224',\n",
              " 'deit_base_patch16_384',\n",
              " 'deit_small_distilled_patch16_224',\n",
              " 'deit_small_patch16_224',\n",
              " 'deit_tiny_distilled_patch16_224',\n",
              " 'deit_tiny_patch16_224',\n",
              " 'densenet121',\n",
              " 'densenet121d',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'densenet264',\n",
              " 'densenet264d_iabn',\n",
              " 'densenetblur121d',\n",
              " 'dla34',\n",
              " 'dla46_c',\n",
              " 'dla46x_c',\n",
              " 'dla60',\n",
              " 'dla60_res2net',\n",
              " 'dla60_res2next',\n",
              " 'dla60x',\n",
              " 'dla60x_c',\n",
              " 'dla102',\n",
              " 'dla102x',\n",
              " 'dla102x2',\n",
              " 'dla169',\n",
              " 'dm_nfnet_f0',\n",
              " 'dm_nfnet_f1',\n",
              " 'dm_nfnet_f2',\n",
              " 'dm_nfnet_f3',\n",
              " 'dm_nfnet_f4',\n",
              " 'dm_nfnet_f5',\n",
              " 'dm_nfnet_f6',\n",
              " 'dpn68',\n",
              " 'dpn68b',\n",
              " 'dpn92',\n",
              " 'dpn98',\n",
              " 'dpn107',\n",
              " 'dpn131',\n",
              " 'eca_botnext26ts_256',\n",
              " 'eca_halonext26ts',\n",
              " 'eca_nfnet_l0',\n",
              " 'eca_nfnet_l1',\n",
              " 'eca_nfnet_l2',\n",
              " 'eca_nfnet_l3',\n",
              " 'eca_resnet33ts',\n",
              " 'eca_resnext26ts',\n",
              " 'eca_vovnet39b',\n",
              " 'ecaresnet26t',\n",
              " 'ecaresnet50d',\n",
              " 'ecaresnet50d_pruned',\n",
              " 'ecaresnet50t',\n",
              " 'ecaresnet101d',\n",
              " 'ecaresnet101d_pruned',\n",
              " 'ecaresnet200d',\n",
              " 'ecaresnet269d',\n",
              " 'ecaresnetlight',\n",
              " 'ecaresnext26t_32x4d',\n",
              " 'ecaresnext50t_32x4d',\n",
              " 'edgenext_base',\n",
              " 'edgenext_small',\n",
              " 'edgenext_small_rw',\n",
              " 'edgenext_x_small',\n",
              " 'edgenext_xx_small',\n",
              " 'efficientformer_l1',\n",
              " 'efficientformer_l3',\n",
              " 'efficientformer_l7',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b0_g8_gn',\n",
              " 'efficientnet_b0_g16_evos',\n",
              " 'efficientnet_b0_gn',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b1_pruned',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b2_pruned',\n",
              " 'efficientnet_b2a',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b3_g8_gn',\n",
              " 'efficientnet_b3_gn',\n",
              " 'efficientnet_b3_pruned',\n",
              " 'efficientnet_b3a',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_b8',\n",
              " 'efficientnet_cc_b0_4e',\n",
              " 'efficientnet_cc_b0_8e',\n",
              " 'efficientnet_cc_b1_8e',\n",
              " 'efficientnet_el',\n",
              " 'efficientnet_el_pruned',\n",
              " 'efficientnet_em',\n",
              " 'efficientnet_es',\n",
              " 'efficientnet_es_pruned',\n",
              " 'efficientnet_l2',\n",
              " 'efficientnet_lite0',\n",
              " 'efficientnet_lite1',\n",
              " 'efficientnet_lite2',\n",
              " 'efficientnet_lite3',\n",
              " 'efficientnet_lite4',\n",
              " 'efficientnetv2_l',\n",
              " 'efficientnetv2_m',\n",
              " 'efficientnetv2_rw_m',\n",
              " 'efficientnetv2_rw_s',\n",
              " 'efficientnetv2_rw_t',\n",
              " 'efficientnetv2_s',\n",
              " 'efficientnetv2_xl',\n",
              " 'ens_adv_inception_resnet_v2',\n",
              " 'ese_vovnet19b_dw',\n",
              " 'ese_vovnet19b_slim',\n",
              " 'ese_vovnet19b_slim_dw',\n",
              " 'ese_vovnet39b',\n",
              " 'ese_vovnet39b_evos',\n",
              " 'ese_vovnet57b',\n",
              " 'ese_vovnet99b',\n",
              " 'ese_vovnet99b_iabn',\n",
              " 'fbnetc_100',\n",
              " 'fbnetv3_b',\n",
              " 'fbnetv3_d',\n",
              " 'fbnetv3_g',\n",
              " 'gc_efficientnetv2_rw_t',\n",
              " 'gcresnet33ts',\n",
              " 'gcresnet50t',\n",
              " 'gcresnext26ts',\n",
              " 'gcresnext50ts',\n",
              " 'gcvit_base',\n",
              " 'gcvit_small',\n",
              " 'gcvit_tiny',\n",
              " 'gcvit_xtiny',\n",
              " 'gcvit_xxtiny',\n",
              " 'gernet_l',\n",
              " 'gernet_m',\n",
              " 'gernet_s',\n",
              " 'ghostnet_050',\n",
              " 'ghostnet_100',\n",
              " 'ghostnet_130',\n",
              " 'gluon_inception_v3',\n",
              " 'gluon_resnet18_v1b',\n",
              " 'gluon_resnet34_v1b',\n",
              " 'gluon_resnet50_v1b',\n",
              " 'gluon_resnet50_v1c',\n",
              " 'gluon_resnet50_v1d',\n",
              " 'gluon_resnet50_v1s',\n",
              " 'gluon_resnet101_v1b',\n",
              " 'gluon_resnet101_v1c',\n",
              " 'gluon_resnet101_v1d',\n",
              " 'gluon_resnet101_v1s',\n",
              " 'gluon_resnet152_v1b',\n",
              " 'gluon_resnet152_v1c',\n",
              " 'gluon_resnet152_v1d',\n",
              " 'gluon_resnet152_v1s',\n",
              " 'gluon_resnext50_32x4d',\n",
              " 'gluon_resnext101_32x4d',\n",
              " 'gluon_resnext101_64x4d',\n",
              " 'gluon_senet154',\n",
              " 'gluon_seresnext50_32x4d',\n",
              " 'gluon_seresnext101_32x4d',\n",
              " 'gluon_seresnext101_64x4d',\n",
              " 'gluon_xception65',\n",
              " 'gmixer_12_224',\n",
              " 'gmixer_24_224',\n",
              " 'gmlp_b16_224',\n",
              " 'gmlp_s16_224',\n",
              " 'gmlp_ti16_224',\n",
              " 'halo2botnet50ts_256',\n",
              " 'halonet26t',\n",
              " 'halonet50ts',\n",
              " 'halonet_h1',\n",
              " 'haloregnetz_b',\n",
              " 'hardcorenas_a',\n",
              " 'hardcorenas_b',\n",
              " 'hardcorenas_c',\n",
              " 'hardcorenas_d',\n",
              " 'hardcorenas_e',\n",
              " 'hardcorenas_f',\n",
              " 'hrnet_w18',\n",
              " 'hrnet_w18_small',\n",
              " 'hrnet_w18_small_v2',\n",
              " 'hrnet_w30',\n",
              " 'hrnet_w32',\n",
              " 'hrnet_w40',\n",
              " 'hrnet_w44',\n",
              " 'hrnet_w48',\n",
              " 'hrnet_w64',\n",
              " 'ig_resnext101_32x8d',\n",
              " 'ig_resnext101_32x16d',\n",
              " 'ig_resnext101_32x32d',\n",
              " 'ig_resnext101_32x48d',\n",
              " 'inception_resnet_v2',\n",
              " 'inception_v3',\n",
              " 'inception_v4',\n",
              " 'jx_nest_base',\n",
              " 'jx_nest_small',\n",
              " 'jx_nest_tiny',\n",
              " 'lambda_resnet26rpt_256',\n",
              " 'lambda_resnet26t',\n",
              " 'lambda_resnet50ts',\n",
              " 'lamhalobotnet50ts_256',\n",
              " 'lcnet_035',\n",
              " 'lcnet_050',\n",
              " 'lcnet_075',\n",
              " 'lcnet_100',\n",
              " 'lcnet_150',\n",
              " 'legacy_senet154',\n",
              " 'legacy_seresnet18',\n",
              " 'legacy_seresnet34',\n",
              " 'legacy_seresnet50',\n",
              " 'legacy_seresnet101',\n",
              " 'legacy_seresnet152',\n",
              " 'legacy_seresnext26_32x4d',\n",
              " 'legacy_seresnext50_32x4d',\n",
              " 'legacy_seresnext101_32x4d',\n",
              " 'levit_128',\n",
              " 'levit_128s',\n",
              " 'levit_192',\n",
              " 'levit_256',\n",
              " 'levit_256d',\n",
              " 'levit_384',\n",
              " 'maxvit_base_224',\n",
              " 'maxvit_large_224',\n",
              " 'maxvit_nano_rw_256',\n",
              " 'maxvit_pico_rw_256',\n",
              " 'maxvit_rmlp_nano_rw_256',\n",
              " 'maxvit_rmlp_pico_rw_256',\n",
              " 'maxvit_rmlp_small_rw_224',\n",
              " 'maxvit_rmlp_small_rw_256',\n",
              " 'maxvit_rmlp_tiny_rw_256',\n",
              " 'maxvit_small_224',\n",
              " 'maxvit_tiny_224',\n",
              " 'maxvit_tiny_pm_256',\n",
              " 'maxvit_tiny_rw_224',\n",
              " 'maxvit_tiny_rw_256',\n",
              " 'maxvit_xlarge_224',\n",
              " 'maxxvit_nano_rw_256',\n",
              " 'maxxvit_small_rw_256',\n",
              " 'maxxvit_tiny_rw_256',\n",
              " 'mixer_b16_224',\n",
              " 'mixer_b16_224_in21k',\n",
              " 'mixer_b16_224_miil',\n",
              " 'mixer_b16_224_miil_in21k',\n",
              " 'mixer_b32_224',\n",
              " 'mixer_l16_224',\n",
              " 'mixer_l16_224_in21k',\n",
              " 'mixer_l32_224',\n",
              " 'mixer_s16_224',\n",
              " 'mixer_s32_224',\n",
              " 'mixnet_l',\n",
              " 'mixnet_m',\n",
              " 'mixnet_s',\n",
              " 'mixnet_xl',\n",
              " 'mixnet_xxl',\n",
              " 'mnasnet_050',\n",
              " 'mnasnet_075',\n",
              " 'mnasnet_100',\n",
              " 'mnasnet_140',\n",
              " 'mnasnet_a1',\n",
              " 'mnasnet_b1',\n",
              " 'mnasnet_small',\n",
              " 'mobilenetv2_035',\n",
              " 'mobilenetv2_050',\n",
              " 'mobilenetv2_075',\n",
              " 'mobilenetv2_100',\n",
              " 'mobilenetv2_110d',\n",
              " 'mobilenetv2_120d',\n",
              " 'mobilenetv2_140',\n",
              " 'mobilenetv3_large_075',\n",
              " 'mobilenetv3_large_100',\n",
              " 'mobilenetv3_large_100_miil',\n",
              " 'mobilenetv3_large_100_miil_in21k',\n",
              " 'mobilenetv3_rw',\n",
              " 'mobilenetv3_small_050',\n",
              " 'mobilenetv3_small_075',\n",
              " 'mobilenetv3_small_100',\n",
              " 'mobilevit_s',\n",
              " 'mobilevit_xs',\n",
              " 'mobilevit_xxs',\n",
              " 'mobilevitv2_050',\n",
              " 'mobilevitv2_075',\n",
              " 'mobilevitv2_100',\n",
              " 'mobilevitv2_125',\n",
              " 'mobilevitv2_150',\n",
              " 'mobilevitv2_150_384_in22ft1k',\n",
              " 'mobilevitv2_150_in22ft1k',\n",
              " 'mobilevitv2_175',\n",
              " 'mobilevitv2_175_384_in22ft1k',\n",
              " 'mobilevitv2_175_in22ft1k',\n",
              " 'mobilevitv2_200',\n",
              " 'mobilevitv2_200_384_in22ft1k',\n",
              " 'mobilevitv2_200_in22ft1k',\n",
              " 'mvitv2_base',\n",
              " 'mvitv2_large',\n",
              " 'mvitv2_small',\n",
              " 'mvitv2_small_cls',\n",
              " 'mvitv2_tiny',\n",
              " 'nasnetalarge',\n",
              " 'nest_base',\n",
              " 'nest_small',\n",
              " 'nest_tiny',\n",
              " 'nf_ecaresnet26',\n",
              " 'nf_ecaresnet50',\n",
              " 'nf_ecaresnet101',\n",
              " 'nf_regnet_b0',\n",
              " 'nf_regnet_b1',\n",
              " 'nf_regnet_b2',\n",
              " 'nf_regnet_b3',\n",
              " 'nf_regnet_b4',\n",
              " 'nf_regnet_b5',\n",
              " 'nf_resnet26',\n",
              " 'nf_resnet50',\n",
              " 'nf_resnet101',\n",
              " 'nf_seresnet26',\n",
              " 'nf_seresnet50',\n",
              " 'nf_seresnet101',\n",
              " 'nfnet_f0',\n",
              " 'nfnet_f1',\n",
              " 'nfnet_f2',\n",
              " 'nfnet_f3',\n",
              " 'nfnet_f4',\n",
              " 'nfnet_f5',\n",
              " 'nfnet_f6',\n",
              " 'nfnet_f7',\n",
              " 'nfnet_l0',\n",
              " 'pit_b_224',\n",
              " 'pit_b_distilled_224',\n",
              " 'pit_s_224',\n",
              " 'pit_s_distilled_224',\n",
              " 'pit_ti_224',\n",
              " 'pit_ti_distilled_224',\n",
              " 'pit_xs_224',\n",
              " 'pit_xs_distilled_224',\n",
              " 'pnasnet5large',\n",
              " 'poolformer_m36',\n",
              " 'poolformer_m48',\n",
              " 'poolformer_s12',\n",
              " 'poolformer_s24',\n",
              " 'poolformer_s36',\n",
              " 'pvt_v2_b0',\n",
              " 'pvt_v2_b1',\n",
              " 'pvt_v2_b2',\n",
              " 'pvt_v2_b2_li',\n",
              " 'pvt_v2_b3',\n",
              " 'pvt_v2_b4',\n",
              " 'pvt_v2_b5',\n",
              " 'regnetv_040',\n",
              " 'regnetv_064',\n",
              " 'regnetx_002',\n",
              " 'regnetx_004',\n",
              " 'regnetx_006',\n",
              " 'regnetx_008',\n",
              " 'regnetx_016',\n",
              " 'regnetx_032',\n",
              " 'regnetx_040',\n",
              " 'regnetx_064',\n",
              " 'regnetx_080',\n",
              " 'regnetx_120',\n",
              " 'regnetx_160',\n",
              " 'regnetx_320',\n",
              " 'regnety_002',\n",
              " 'regnety_004',\n",
              " 'regnety_006',\n",
              " 'regnety_008',\n",
              " 'regnety_016',\n",
              " 'regnety_032',\n",
              " 'regnety_040',\n",
              " 'regnety_040s_gn',\n",
              " 'regnety_064',\n",
              " 'regnety_080',\n",
              " 'regnety_120',\n",
              " 'regnety_160',\n",
              " 'regnety_320',\n",
              " 'regnetz_005',\n",
              " 'regnetz_040',\n",
              " 'regnetz_040h',\n",
              " 'regnetz_b16',\n",
              " 'regnetz_b16_evos',\n",
              " 'regnetz_c16',\n",
              " 'regnetz_c16_evos',\n",
              " 'regnetz_d8',\n",
              " 'regnetz_d8_evos',\n",
              " 'regnetz_d32',\n",
              " 'regnetz_e8',\n",
              " 'repvgg_a2',\n",
              " 'repvgg_b0',\n",
              " 'repvgg_b1',\n",
              " 'repvgg_b1g4',\n",
              " 'repvgg_b2',\n",
              " 'repvgg_b2g4',\n",
              " 'repvgg_b3',\n",
              " 'repvgg_b3g4',\n",
              " 'res2net50_14w_8s',\n",
              " 'res2net50_26w_4s',\n",
              " 'res2net50_26w_6s',\n",
              " 'res2net50_26w_8s',\n",
              " 'res2net50_48w_2s',\n",
              " 'res2net101_26w_4s',\n",
              " 'res2next50',\n",
              " 'resmlp_12_224',\n",
              " 'resmlp_12_224_dino',\n",
              " 'resmlp_12_distilled_224',\n",
              " 'resmlp_24_224',\n",
              " 'resmlp_24_224_dino',\n",
              " 'resmlp_24_distilled_224',\n",
              " 'resmlp_36_224',\n",
              " 'resmlp_36_distilled_224',\n",
              " 'resmlp_big_24_224',\n",
              " 'resmlp_big_24_224_in22ft1k',\n",
              " 'resmlp_big_24_distilled_224',\n",
              " 'resnest14d',\n",
              " 'resnest26d',\n",
              " 'resnest50d',\n",
              " 'resnest50d_1s4x24d',\n",
              " 'resnest50d_4s2x40d',\n",
              " 'resnest101e',\n",
              " 'resnest200e',\n",
              " 'resnest269e',\n",
              " 'resnet10t',\n",
              " 'resnet14t',\n",
              " 'resnet18',\n",
              " 'resnet18d',\n",
              " 'resnet26',\n",
              " 'resnet26d',\n",
              " 'resnet26t',\n",
              " 'resnet32ts',\n",
              " 'resnet33ts',\n",
              " 'resnet34',\n",
              " 'resnet34d',\n",
              " 'resnet50',\n",
              " 'resnet50_gn',\n",
              " 'resnet50d',\n",
              " 'resnet50t',\n",
              " 'resnet51q',\n",
              " 'resnet61q',\n",
              " 'resnet101',\n",
              " 'resnet101d',\n",
              " 'resnet152',\n",
              " 'resnet152d',\n",
              " 'resnet200',\n",
              " 'resnet200d',\n",
              " 'resnetaa50',\n",
              " 'resnetaa50d',\n",
              " 'resnetaa101d',\n",
              " 'resnetblur18',\n",
              " 'resnetblur50',\n",
              " 'resnetblur50d',\n",
              " 'resnetblur101d',\n",
              " 'resnetrs50',\n",
              " 'resnetrs101',\n",
              " 'resnetrs152',\n",
              " 'resnetrs200',\n",
              " 'resnetrs270',\n",
              " 'resnetrs350',\n",
              " 'resnetrs420',\n",
              " 'resnetv2_50',\n",
              " 'resnetv2_50d',\n",
              " 'resnetv2_50d_evob',\n",
              " 'resnetv2_50d_evos',\n",
              " 'resnetv2_50d_frn',\n",
              " 'resnetv2_50d_gn',\n",
              " 'resnetv2_50t',\n",
              " 'resnetv2_50x1_bit_distilled',\n",
              " 'resnetv2_50x1_bitm',\n",
              " 'resnetv2_50x1_bitm_in21k',\n",
              " 'resnetv2_50x3_bitm',\n",
              " 'resnetv2_50x3_bitm_in21k',\n",
              " 'resnetv2_101',\n",
              " 'resnetv2_101d',\n",
              " 'resnetv2_101x1_bitm',\n",
              " 'resnetv2_101x1_bitm_in21k',\n",
              " 'resnetv2_101x3_bitm',\n",
              " 'resnetv2_101x3_bitm_in21k',\n",
              " 'resnetv2_152',\n",
              " 'resnetv2_152d',\n",
              " 'resnetv2_152x2_bit_teacher',\n",
              " 'resnetv2_152x2_bit_teacher_384',\n",
              " 'resnetv2_152x2_bitm',\n",
              " 'resnetv2_152x2_bitm_in21k',\n",
              " 'resnetv2_152x4_bitm',\n",
              " 'resnetv2_152x4_bitm_in21k',\n",
              " 'resnext26ts',\n",
              " 'resnext50_32x4d',\n",
              " 'resnext50d_32x4d',\n",
              " 'resnext101_32x4d',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'rexnet_100',\n",
              " 'rexnet_130',\n",
              " 'rexnet_150',\n",
              " 'rexnet_200',\n",
              " 'rexnetr_100',\n",
              " 'rexnetr_130',\n",
              " 'rexnetr_150',\n",
              " 'rexnetr_200',\n",
              " 'sebotnet33ts_256',\n",
              " 'sedarknet21',\n",
              " 'sehalonet33ts',\n",
              " 'selecsls42',\n",
              " 'selecsls42b',\n",
              " 'selecsls60',\n",
              " 'selecsls60b',\n",
              " 'selecsls84',\n",
              " 'semnasnet_050',\n",
              " 'semnasnet_075',\n",
              " 'semnasnet_100',\n",
              " 'semnasnet_140',\n",
              " 'semobilevit_s',\n",
              " 'senet154',\n",
              " 'sequencer2d_l',\n",
              " 'sequencer2d_m',\n",
              " 'sequencer2d_s',\n",
              " 'seresnet18',\n",
              " 'seresnet33ts',\n",
              " 'seresnet34',\n",
              " 'seresnet50',\n",
              " 'seresnet50t',\n",
              " 'seresnet101',\n",
              " 'seresnet152',\n",
              " 'seresnet152d',\n",
              " 'seresnet200d',\n",
              " 'seresnet269d',\n",
              " 'seresnetaa50d',\n",
              " 'seresnext26d_32x4d',\n",
              " 'seresnext26t_32x4d',\n",
              " 'seresnext26tn_32x4d',\n",
              " 'seresnext26ts',\n",
              " 'seresnext50_32x4d',\n",
              " 'seresnext101_32x4d',\n",
              " 'seresnext101_32x8d',\n",
              " 'seresnext101d_32x8d',\n",
              " 'seresnextaa101d_32x8d',\n",
              " 'skresnet18',\n",
              " 'skresnet34',\n",
              " 'skresnet50',\n",
              " 'skresnet50d',\n",
              " 'skresnext50_32x4d',\n",
              " 'spnasnet_100',\n",
              " 'ssl_resnet18',\n",
              " 'ssl_resnet50',\n",
              " 'ssl_resnext50_32x4d',\n",
              " 'ssl_resnext101_32x4d',\n",
              " 'ssl_resnext101_32x8d',\n",
              " 'ssl_resnext101_32x16d',\n",
              " 'swin_base_patch4_window7_224',\n",
              " 'swin_base_patch4_window7_224_in22k',\n",
              " 'swin_base_patch4_window12_384',\n",
              " 'swin_base_patch4_window12_384_in22k',\n",
              " 'swin_large_patch4_window7_224',\n",
              " 'swin_large_patch4_window7_224_in22k',\n",
              " 'swin_large_patch4_window12_384',\n",
              " 'swin_large_patch4_window12_384_in22k',\n",
              " 'swin_s3_base_224',\n",
              " 'swin_s3_small_224',\n",
              " 'swin_s3_tiny_224',\n",
              " 'swin_small_patch4_window7_224',\n",
              " 'swin_tiny_patch4_window7_224',\n",
              " 'swinv2_base_window8_256',\n",
              " 'swinv2_base_window12_192_22k',\n",
              " 'swinv2_base_window12to16_192to256_22kft1k',\n",
              " 'swinv2_base_window12to24_192to384_22kft1k',\n",
              " 'swinv2_base_window16_256',\n",
              " 'swinv2_cr_base_224',\n",
              " 'swinv2_cr_base_384',\n",
              " 'swinv2_cr_base_ns_224',\n",
              " 'swinv2_cr_giant_224',\n",
              " 'swinv2_cr_giant_384',\n",
              " 'swinv2_cr_huge_224',\n",
              " 'swinv2_cr_huge_384',\n",
              " 'swinv2_cr_large_224',\n",
              " 'swinv2_cr_large_384',\n",
              " 'swinv2_cr_small_224',\n",
              " 'swinv2_cr_small_384',\n",
              " 'swinv2_cr_small_ns_224',\n",
              " 'swinv2_cr_tiny_224',\n",
              " 'swinv2_cr_tiny_384',\n",
              " 'swinv2_cr_tiny_ns_224',\n",
              " 'swinv2_large_window12_192_22k',\n",
              " 'swinv2_large_window12to16_192to256_22kft1k',\n",
              " 'swinv2_large_window12to24_192to384_22kft1k',\n",
              " 'swinv2_small_window8_256',\n",
              " 'swinv2_small_window16_256',\n",
              " 'swinv2_tiny_window8_256',\n",
              " 'swinv2_tiny_window16_256',\n",
              " 'swsl_resnet18',\n",
              " 'swsl_resnet50',\n",
              " 'swsl_resnext50_32x4d',\n",
              " 'swsl_resnext101_32x4d',\n",
              " 'swsl_resnext101_32x8d',\n",
              " 'swsl_resnext101_32x16d',\n",
              " 'tf_efficientnet_b0',\n",
              " 'tf_efficientnet_b0_ap',\n",
              " 'tf_efficientnet_b0_ns',\n",
              " 'tf_efficientnet_b1',\n",
              " 'tf_efficientnet_b1_ap',\n",
              " 'tf_efficientnet_b1_ns',\n",
              " 'tf_efficientnet_b2',\n",
              " 'tf_efficientnet_b2_ap',\n",
              " 'tf_efficientnet_b2_ns',\n",
              " 'tf_efficientnet_b3',\n",
              " 'tf_efficientnet_b3_ap',\n",
              " 'tf_efficientnet_b3_ns',\n",
              " 'tf_efficientnet_b4',\n",
              " 'tf_efficientnet_b4_ap',\n",
              " 'tf_efficientnet_b4_ns',\n",
              " 'tf_efficientnet_b5',\n",
              " 'tf_efficientnet_b5_ap',\n",
              " 'tf_efficientnet_b5_ns',\n",
              " 'tf_efficientnet_b6',\n",
              " 'tf_efficientnet_b6_ap',\n",
              " 'tf_efficientnet_b6_ns',\n",
              " 'tf_efficientnet_b7',\n",
              " 'tf_efficientnet_b7_ap',\n",
              " 'tf_efficientnet_b7_ns',\n",
              " 'tf_efficientnet_b8',\n",
              " 'tf_efficientnet_b8_ap',\n",
              " 'tf_efficientnet_cc_b0_4e',\n",
              " 'tf_efficientnet_cc_b0_8e',\n",
              " 'tf_efficientnet_cc_b1_8e',\n",
              " 'tf_efficientnet_el',\n",
              " 'tf_efficientnet_em',\n",
              " 'tf_efficientnet_es',\n",
              " 'tf_efficientnet_l2_ns',\n",
              " 'tf_efficientnet_l2_ns_475',\n",
              " 'tf_efficientnet_lite0',\n",
              " 'tf_efficientnet_lite1',\n",
              " 'tf_efficientnet_lite2',\n",
              " 'tf_efficientnet_lite3',\n",
              " 'tf_efficientnet_lite4',\n",
              " 'tf_efficientnetv2_b0',\n",
              " 'tf_efficientnetv2_b1',\n",
              " 'tf_efficientnetv2_b2',\n",
              " 'tf_efficientnetv2_b3',\n",
              " 'tf_efficientnetv2_l',\n",
              " 'tf_efficientnetv2_l_in21ft1k',\n",
              " 'tf_efficientnetv2_l_in21k',\n",
              " 'tf_efficientnetv2_m',\n",
              " 'tf_efficientnetv2_m_in21ft1k',\n",
              " 'tf_efficientnetv2_m_in21k',\n",
              " 'tf_efficientnetv2_s',\n",
              " 'tf_efficientnetv2_s_in21ft1k',\n",
              " 'tf_efficientnetv2_s_in21k',\n",
              " 'tf_efficientnetv2_xl_in21ft1k',\n",
              " 'tf_efficientnetv2_xl_in21k',\n",
              " 'tf_inception_v3',\n",
              " 'tf_mixnet_l',\n",
              " 'tf_mixnet_m',\n",
              " 'tf_mixnet_s',\n",
              " 'tf_mobilenetv3_large_075',\n",
              " 'tf_mobilenetv3_large_100',\n",
              " 'tf_mobilenetv3_large_minimal_100',\n",
              " 'tf_mobilenetv3_small_075',\n",
              " 'tf_mobilenetv3_small_100',\n",
              " 'tf_mobilenetv3_small_minimal_100',\n",
              " 'tinynet_a',\n",
              " 'tinynet_b',\n",
              " 'tinynet_c',\n",
              " 'tinynet_d',\n",
              " 'tinynet_e',\n",
              " 'tnt_b_patch16_224',\n",
              " 'tnt_s_patch16_224',\n",
              " 'tresnet_l',\n",
              " 'tresnet_l_448',\n",
              " 'tresnet_m',\n",
              " 'tresnet_m_448',\n",
              " 'tresnet_m_miil_in21k',\n",
              " 'tresnet_v2_l',\n",
              " 'tresnet_xl',\n",
              " 'tresnet_xl_448',\n",
              " 'tv_densenet121',\n",
              " 'tv_resnet34',\n",
              " 'tv_resnet50',\n",
              " 'tv_resnet101',\n",
              " 'tv_resnet152',\n",
              " 'tv_resnext50_32x4d',\n",
              " 'twins_pcpvt_base',\n",
              " 'twins_pcpvt_large',\n",
              " 'twins_pcpvt_small',\n",
              " 'twins_svt_base',\n",
              " 'twins_svt_large',\n",
              " 'twins_svt_small',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'visformer_small',\n",
              " 'visformer_tiny',\n",
              " 'vit_base_patch8_224',\n",
              " 'vit_base_patch8_224_dino',\n",
              " 'vit_base_patch8_224_in21k',\n",
              " 'vit_base_patch16_18x2_224',\n",
              " 'vit_base_patch16_224',\n",
              " 'vit_base_patch16_224_dino',\n",
              " 'vit_base_patch16_224_in21k',\n",
              " 'vit_base_patch16_224_miil',\n",
              " 'vit_base_patch16_224_miil_in21k',\n",
              " 'vit_base_patch16_224_sam',\n",
              " 'vit_base_patch16_384',\n",
              " 'vit_base_patch16_plus_240',\n",
              " 'vit_base_patch16_rpn_224',\n",
              " 'vit_base_patch32_224',\n",
              " 'vit_base_patch32_224_clip_laion2b',\n",
              " 'vit_base_patch32_224_in21k',\n",
              " 'vit_base_patch32_224_sam',\n",
              " 'vit_base_patch32_384',\n",
              " 'vit_base_patch32_plus_256',\n",
              " 'vit_base_r26_s32_224',\n",
              " 'vit_base_r50_s16_224',\n",
              " 'vit_base_r50_s16_224_in21k',\n",
              " 'vit_base_r50_s16_384',\n",
              " 'vit_base_resnet26d_224',\n",
              " 'vit_base_resnet50_224_in21k',\n",
              " 'vit_base_resnet50_384',\n",
              " 'vit_base_resnet50d_224',\n",
              " 'vit_giant_patch14_224',\n",
              " 'vit_giant_patch14_224_clip_laion2b',\n",
              " 'vit_gigantic_patch14_224',\n",
              " 'vit_huge_patch14_224',\n",
              " 'vit_huge_patch14_224_clip_laion2b',\n",
              " 'vit_huge_patch14_224_in21k',\n",
              " 'vit_large_patch14_224',\n",
              " 'vit_large_patch14_224_clip_laion2b',\n",
              " 'vit_large_patch16_224',\n",
              " 'vit_large_patch16_224_in21k',\n",
              " 'vit_large_patch16_384',\n",
              " 'vit_large_patch32_224',\n",
              " 'vit_large_patch32_224_in21k',\n",
              " 'vit_large_patch32_384',\n",
              " 'vit_large_r50_s32_224',\n",
              " 'vit_large_r50_s32_224_in21k',\n",
              " 'vit_large_r50_s32_384',\n",
              " 'vit_relpos_base_patch16_224',\n",
              " 'vit_relpos_base_patch16_cls_224',\n",
              " 'vit_relpos_base_patch16_clsgap_224',\n",
              " 'vit_relpos_base_patch16_plus_240',\n",
              " 'vit_relpos_base_patch16_rpn_224',\n",
              " 'vit_relpos_base_patch32_plus_rpn_256',\n",
              " 'vit_relpos_medium_patch16_224',\n",
              " 'vit_relpos_medium_patch16_cls_224',\n",
              " 'vit_relpos_medium_patch16_rpn_224',\n",
              " 'vit_relpos_small_patch16_224',\n",
              " 'vit_relpos_small_patch16_rpn_224',\n",
              " 'vit_small_patch8_224_dino',\n",
              " 'vit_small_patch16_18x2_224',\n",
              " 'vit_small_patch16_36x1_224',\n",
              " 'vit_small_patch16_224',\n",
              " 'vit_small_patch16_224_dino',\n",
              " 'vit_small_patch16_224_in21k',\n",
              " 'vit_small_patch16_384',\n",
              " 'vit_small_patch32_224',\n",
              " 'vit_small_patch32_224_in21k',\n",
              " 'vit_small_patch32_384',\n",
              " 'vit_small_r26_s32_224',\n",
              " 'vit_small_r26_s32_224_in21k',\n",
              " 'vit_small_r26_s32_384',\n",
              " 'vit_small_resnet26d_224',\n",
              " 'vit_small_resnet50d_s16_224',\n",
              " 'vit_srelpos_medium_patch16_224',\n",
              " 'vit_srelpos_small_patch16_224',\n",
              " 'vit_tiny_patch16_224',\n",
              " 'vit_tiny_patch16_224_in21k',\n",
              " 'vit_tiny_patch16_384',\n",
              " 'vit_tiny_r_s16_p8_224',\n",
              " 'vit_tiny_r_s16_p8_224_in21k',\n",
              " 'vit_tiny_r_s16_p8_384',\n",
              " 'volo_d1_224',\n",
              " 'volo_d1_384',\n",
              " 'volo_d2_224',\n",
              " 'volo_d2_384',\n",
              " 'volo_d3_224',\n",
              " 'volo_d3_448',\n",
              " 'volo_d4_224',\n",
              " 'volo_d4_448',\n",
              " 'volo_d5_224',\n",
              " 'volo_d5_448',\n",
              " 'volo_d5_512',\n",
              " 'vovnet39a',\n",
              " 'vovnet57a',\n",
              " 'wide_resnet50_2',\n",
              " 'wide_resnet101_2',\n",
              " 'xception',\n",
              " 'xception41',\n",
              " 'xception41p',\n",
              " 'xception65',\n",
              " 'xception65p',\n",
              " 'xception71',\n",
              " 'xcit_large_24_p8_224',\n",
              " 'xcit_large_24_p8_224_dist',\n",
              " 'xcit_large_24_p8_384_dist',\n",
              " 'xcit_large_24_p16_224',\n",
              " 'xcit_large_24_p16_224_dist',\n",
              " 'xcit_large_24_p16_384_dist',\n",
              " 'xcit_medium_24_p8_224',\n",
              " 'xcit_medium_24_p8_224_dist',\n",
              " 'xcit_medium_24_p8_384_dist',\n",
              " 'xcit_medium_24_p16_224',\n",
              " 'xcit_medium_24_p16_224_dist',\n",
              " 'xcit_medium_24_p16_384_dist',\n",
              " 'xcit_nano_12_p8_224',\n",
              " 'xcit_nano_12_p8_224_dist',\n",
              " 'xcit_nano_12_p8_384_dist',\n",
              " 'xcit_nano_12_p16_224',\n",
              " 'xcit_nano_12_p16_224_dist',\n",
              " 'xcit_nano_12_p16_384_dist',\n",
              " 'xcit_small_12_p8_224',\n",
              " 'xcit_small_12_p8_224_dist',\n",
              " 'xcit_small_12_p8_384_dist',\n",
              " 'xcit_small_12_p16_224',\n",
              " 'xcit_small_12_p16_224_dist',\n",
              " 'xcit_small_12_p16_384_dist',\n",
              " 'xcit_small_24_p8_224',\n",
              " 'xcit_small_24_p8_224_dist',\n",
              " 'xcit_small_24_p8_384_dist',\n",
              " 'xcit_small_24_p16_224',\n",
              " 'xcit_small_24_p16_224_dist',\n",
              " 'xcit_small_24_p16_384_dist',\n",
              " 'xcit_tiny_12_p8_224',\n",
              " 'xcit_tiny_12_p8_224_dist',\n",
              " 'xcit_tiny_12_p8_384_dist',\n",
              " 'xcit_tiny_12_p16_224',\n",
              " 'xcit_tiny_12_p16_224_dist',\n",
              " 'xcit_tiny_12_p16_384_dist',\n",
              " 'xcit_tiny_24_p8_224',\n",
              " 'xcit_tiny_24_p8_224_dist',\n",
              " 'xcit_tiny_24_p8_384_dist',\n",
              " 'xcit_tiny_24_p16_224',\n",
              " 'xcit_tiny_24_p16_224_dist',\n",
              " 'xcit_tiny_24_p16_384_dist']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = timm.create_model('seresnext50_32x4d', pretrained=False, num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "total=0 \n",
        "correct = 0"
      ],
      "metadata": {
        "id": "Os2IBshCP2bO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs= net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 750 ==749:\n",
        "      print(\"Epoch: {},Batch : {}, Loss:{}\".format(epoch+1, i+1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    val_loss = 0.0\n",
        "    for k, data1 in enumerate(vaild_loader, 0):\n",
        "      val_inputs, val_label = data1[0].to(device), data1[1].to(device)\n",
        "      val_output = net(val_inputs)\n",
        "      v_loss = criterion(val_output, val_label)\n",
        "      val_loss += v_loss\n",
        "  print(\"validation loss : {}\".format(val_loss))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs= net(images)\n",
        "      _, predicted = torch.max(outputs.data,1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(\"testset Accuracy  : {}\".format(100* correct/total))\n",
        "  total=0\n",
        "  correct=0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q8IufYT0P4Zx",
        "outputId": "ca987877-4a73-4121-cc0f-5f9fea32c0f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1,Batch : 750, Loss:0.8087673770785332\n",
            "Epoch: 1,Batch : 1500, Loss:0.7966346333026886\n",
            "validation loss : 329.7434387207031\n",
            "testset Accuracy  : 12.5\n",
            "Epoch: 2,Batch : 750, Loss:0.7924044521450997\n",
            "Epoch: 2,Batch : 1500, Loss:0.7864971287250518\n",
            "validation loss : 324.31103515625\n",
            "testset Accuracy  : 11.15\n",
            "Epoch: 3,Batch : 750, Loss:0.7802423387765884\n",
            "Epoch: 3,Batch : 1500, Loss:0.7747168978452682\n",
            "validation loss : 318.93682861328125\n",
            "testset Accuracy  : 9.75\n",
            "Epoch: 4,Batch : 750, Loss:0.7501995128393173\n",
            "Epoch: 4,Batch : 1500, Loss:0.7095729603767394\n",
            "validation loss : 285.6237487792969\n",
            "testset Accuracy  : 10.2\n",
            "Epoch: 5,Batch : 750, Loss:0.6708830471038818\n",
            "Epoch: 5,Batch : 1500, Loss:0.6413659662008285\n",
            "validation loss : 259.1941223144531\n",
            "testset Accuracy  : 10.0\n",
            "Epoch: 6,Batch : 750, Loss:0.6070097264647484\n",
            "Epoch: 6,Batch : 1500, Loss:0.5911159485578537\n",
            "validation loss : 239.54129028320312\n",
            "testset Accuracy  : 10.55\n",
            "Epoch: 7,Batch : 750, Loss:0.5559819714426995\n",
            "Epoch: 7,Batch : 1500, Loss:0.5471249656677246\n",
            "validation loss : 225.6838836669922\n",
            "testset Accuracy  : 10.95\n",
            "Epoch: 8,Batch : 750, Loss:0.5155656991004944\n",
            "Epoch: 8,Batch : 1500, Loss:0.5095426200032234\n",
            "validation loss : 212.54437255859375\n",
            "testset Accuracy  : 11.55\n",
            "Epoch: 9,Batch : 750, Loss:0.48544234013557436\n",
            "Epoch: 9,Batch : 1500, Loss:0.47696031150221824\n",
            "validation loss : 203.06640625\n",
            "testset Accuracy  : 10.7\n",
            "Epoch: 10,Batch : 750, Loss:0.45359042820334433\n",
            "Epoch: 10,Batch : 1500, Loss:0.4482241550683975\n",
            "validation loss : 195.52420043945312\n",
            "testset Accuracy  : 11.7\n",
            "Epoch: 11,Batch : 750, Loss:0.4261904349029064\n",
            "Epoch: 11,Batch : 1500, Loss:0.4213045232594013\n",
            "validation loss : 192.9129180908203\n",
            "testset Accuracy  : 11.4\n",
            "Epoch: 12,Batch : 750, Loss:0.39906652754545213\n",
            "Epoch: 12,Batch : 1500, Loss:0.39892847830057143\n",
            "validation loss : 185.84268188476562\n",
            "testset Accuracy  : 12.25\n",
            "Epoch: 13,Batch : 750, Loss:0.3736603493094444\n",
            "Epoch: 13,Batch : 1500, Loss:0.3769713789373636\n",
            "validation loss : 181.83319091796875\n",
            "testset Accuracy  : 12.0\n",
            "Epoch: 14,Batch : 750, Loss:0.35437151190638544\n",
            "Epoch: 14,Batch : 1500, Loss:0.35109998129308223\n",
            "validation loss : 178.1258544921875\n",
            "testset Accuracy  : 12.9\n",
            "Epoch: 15,Batch : 750, Loss:0.33218707534670827\n",
            "Epoch: 15,Batch : 1500, Loss:0.33494692178070545\n",
            "validation loss : 173.262939453125\n",
            "testset Accuracy  : 13.1\n",
            "Epoch: 16,Batch : 750, Loss:0.30717213642597196\n",
            "Epoch: 16,Batch : 1500, Loss:0.3192688250243664\n",
            "validation loss : 172.21392822265625\n",
            "testset Accuracy  : 12.3\n",
            "Epoch: 17,Batch : 750, Loss:0.2879839913845062\n",
            "Epoch: 17,Batch : 1500, Loss:0.30207745742797854\n",
            "validation loss : 168.56497192382812\n",
            "testset Accuracy  : 12.95\n",
            "Epoch: 18,Batch : 750, Loss:0.27344713881611826\n",
            "Epoch: 18,Batch : 1500, Loss:0.2818717703819275\n",
            "validation loss : 169.0992889404297\n",
            "testset Accuracy  : 13.05\n",
            "Epoch: 19,Batch : 750, Loss:0.2563128729686141\n",
            "Epoch: 19,Batch : 1500, Loss:0.27121111200749876\n",
            "validation loss : 171.45529174804688\n",
            "testset Accuracy  : 12.2\n",
            "Epoch: 20,Batch : 750, Loss:0.24220531471818685\n",
            "Epoch: 20,Batch : 1500, Loss:0.2547291604727507\n",
            "validation loss : 171.05648803710938\n",
            "testset Accuracy  : 13.1\n",
            "Epoch: 21,Batch : 750, Loss:0.2235601588860154\n",
            "Epoch: 21,Batch : 1500, Loss:0.2417233419716358\n",
            "validation loss : 172.76528930664062\n",
            "testset Accuracy  : 13.3\n",
            "Epoch: 22,Batch : 750, Loss:0.21113296950608493\n",
            "Epoch: 22,Batch : 1500, Loss:0.22590842420607804\n",
            "validation loss : 168.22935485839844\n",
            "testset Accuracy  : 13.75\n",
            "Epoch: 23,Batch : 750, Loss:0.1994436724036932\n",
            "Epoch: 23,Batch : 1500, Loss:0.21326792055368424\n",
            "validation loss : 171.78912353515625\n",
            "testset Accuracy  : 12.6\n",
            "Epoch: 24,Batch : 750, Loss:0.18266875187307596\n",
            "Epoch: 24,Batch : 1500, Loss:0.20154788733273746\n",
            "validation loss : 175.95343017578125\n",
            "testset Accuracy  : 13.2\n",
            "Epoch: 25,Batch : 750, Loss:0.17100575599074364\n",
            "Epoch: 25,Batch : 1500, Loss:0.18789638366550207\n",
            "validation loss : 181.13375854492188\n",
            "testset Accuracy  : 13.1\n",
            "Epoch: 26,Batch : 750, Loss:0.1611677622385323\n",
            "Epoch: 26,Batch : 1500, Loss:0.17607989344745875\n",
            "validation loss : 182.19435119628906\n",
            "testset Accuracy  : 13.55\n",
            "Epoch: 27,Batch : 750, Loss:0.15185193667188288\n",
            "Epoch: 27,Batch : 1500, Loss:0.16873782277479768\n",
            "validation loss : 183.34896850585938\n",
            "testset Accuracy  : 13.5\n",
            "Epoch: 28,Batch : 750, Loss:0.1442635930776596\n",
            "Epoch: 28,Batch : 1500, Loss:0.1527110436670482\n",
            "validation loss : 186.89666748046875\n",
            "testset Accuracy  : 13.35\n",
            "Epoch: 29,Batch : 750, Loss:0.13423072885349394\n",
            "Epoch: 29,Batch : 1500, Loss:0.1487851441577077\n",
            "validation loss : 194.7029266357422\n",
            "testset Accuracy  : 13.35\n",
            "Epoch: 30,Batch : 750, Loss:0.12699525520205499\n",
            "Epoch: 30,Batch : 1500, Loss:0.14483430945128203\n",
            "validation loss : 193.03565979003906\n",
            "testset Accuracy  : 14.2\n",
            "Epoch: 31,Batch : 750, Loss:0.11769874385371805\n",
            "Epoch: 31,Batch : 1500, Loss:0.13077941808849572\n",
            "validation loss : 200.21607971191406\n",
            "testset Accuracy  : 13.35\n",
            "Epoch: 32,Batch : 750, Loss:0.11068140239827334\n",
            "Epoch: 32,Batch : 1500, Loss:0.11824724655225873\n",
            "validation loss : 199.095947265625\n",
            "testset Accuracy  : 13.3\n",
            "Epoch: 33,Batch : 750, Loss:0.10195882619172335\n",
            "Epoch: 33,Batch : 1500, Loss:0.11508331023901701\n",
            "validation loss : 204.01454162597656\n",
            "testset Accuracy  : 12.75\n",
            "Epoch: 34,Batch : 750, Loss:0.09891567236371339\n",
            "Epoch: 34,Batch : 1500, Loss:0.11133546581491828\n",
            "validation loss : 200.2280731201172\n",
            "testset Accuracy  : 12.45\n",
            "Epoch: 35,Batch : 750, Loss:0.09315408509783447\n",
            "Epoch: 35,Batch : 1500, Loss:0.10106019425019622\n",
            "validation loss : 207.82635498046875\n",
            "testset Accuracy  : 14.0\n",
            "Epoch: 36,Batch : 750, Loss:0.08438488971814513\n",
            "Epoch: 36,Batch : 1500, Loss:0.09455945350509137\n",
            "validation loss : 206.69947814941406\n",
            "testset Accuracy  : 13.2\n",
            "Epoch: 37,Batch : 750, Loss:0.08107928471826018\n",
            "Epoch: 37,Batch : 1500, Loss:0.08855894055776298\n",
            "validation loss : 213.6337127685547\n",
            "testset Accuracy  : 12.85\n",
            "Epoch: 38,Batch : 750, Loss:0.07816169433947652\n",
            "Epoch: 38,Batch : 1500, Loss:0.08511373928375542\n",
            "validation loss : 218.55746459960938\n",
            "testset Accuracy  : 13.3\n",
            "Epoch: 39,Batch : 750, Loss:0.07087473699031398\n",
            "Epoch: 39,Batch : 1500, Loss:0.0810705769052729\n",
            "validation loss : 216.5972137451172\n",
            "testset Accuracy  : 13.6\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-aef6fe1c5fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/resnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/timm/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pretrained 넣기\n"
      ],
      "metadata": {
        "id": "KqDJoCltxkKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/share/trained_model/cifar_effnetv2_s.pth'\n",
        "\n"
      ],
      "metadata": {
        "id": "S0fKwJo7P4iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "9VJnnqHYI-Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane','automobile','bird','cat','deer',\n",
        "           'dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "47ZGkY0NX5if"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    c= (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label= labels[i]\n",
        "      class_correct[label]+= c[i].item()\n",
        "      class_total[label]+= 1\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Accuracy of {} : {} %\".format(classes[i],100* class_correct[i]/class_total[i]))"
      ],
      "metadata": {
        "id": "QOaHVH52X5kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16e5ed2-dfb2-45d5-9272-38e146433631"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of plane : 14.285714285714286 %\n",
            "Accuracy of automobile : 8.333333333333334 %\n",
            "Accuracy of bird : 8.333333333333334 %\n",
            "Accuracy of cat : 8.333333333333334 %\n",
            "Accuracy of deer : 10.714285714285714 %\n",
            "Accuracy of dog : 12.5 %\n",
            "Accuracy of frog : 20.833333333333332 %\n",
            "Accuracy of horse : 8.333333333333334 %\n",
            "Accuracy of ship : 10.714285714285714 %\n",
            "Accuracy of truck : 16.666666666666668 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLanzQjcfLzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"trainset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44HdYYfb5Eja",
        "outputId": "d8046975-ecb8-424f-fa7c-00c8d3199919"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainset Accuracy  : 94.282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in vaild_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"vaildset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "id": "xKUJChxdX5Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df54a57-496e-4a20-ad1b-a010dc9d1c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vaildset Accuracy  : 78.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"testset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "id": "O8NlBkmgX5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f43da4-bfb0-49f9-c552-9b1a58d06b84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset Accuracy  : 13.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Hfizy9LCavz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}