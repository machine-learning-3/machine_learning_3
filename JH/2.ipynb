{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import math\n",
        "import os"
      ],
      "metadata": {
        "id": "lTTZLf1-R2Ds"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed28a131-7dcf-4030-ff60-65837c7635ec",
        "id": "F-Uwjs7XR2Ds"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    seed = 42\n",
        "    device = \"cuda:0\"    \n",
        "        \n",
        "    lr = 1e-3\n",
        "    epochs = 25\n",
        "    batch_size = 32\n",
        "    num_workers = 4\n",
        "    train_5_folds = True\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "seed_everything(config.seed)"
      ],
      "metadata": {
        "id": "Y537CROxR2Dt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba915e8e-bed4-4f19-9ef8-d1bce484b840",
        "id": "qn_fOyhUR2Dt"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jittering = transforms.ColorJitter(brightness = 0.4, contrast = 2, saturation = 0.4)\n",
        "\n",
        "\n",
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "metadata": {
        "id": "70_nXUACR2Dt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform_train1 = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                      transforms.RandomVerticalFlip(p=0.5),\n",
        "                                      transforms.RandomGrayscale(p=1)])\n",
        "\n",
        "transform_train2 = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                      transforms.RandomVerticalFlip(p=0.5),\n",
        "                                      jittering])\n",
        "\n",
        "transform_train3 = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                      transforms.RandomVerticalFlip(p=0.5),\n",
        "                                      AddGaussianNoise(0., 0.01)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "transform  = transforms.Compose([\n",
        "        transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "YeDYgykUR2Dt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset1 = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train1)\n",
        "\n",
        "trainset2 = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train2)\n",
        "\n",
        "trainset3 = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train3)\n",
        "\n",
        "vaildset1 = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=False,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train1)\n",
        "\n",
        "vaildset2 = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=False,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train2)\n",
        "\n",
        "vaildset3 = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=False,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train3)\n",
        "\n",
        "trainset = trainset1 +trainset2+trainset3+vaildset1+vaildset2+vaildset3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2f1ab4-b6ae-4716-9907-7f50bf5db193",
        "id": "4z397PELR2Du"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.ImageFolder(root = \"/content/drive/MyDrive/share/images/Statistical_Deep_Image\",\n",
        "                                           transform = transform)"
      ],
      "metadata": {
        "id": "Zd8-9_oDSQK_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(trainset,\n",
        "                          batch_size = 16,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "test_loader = DataLoader(testset,\n",
        "                          batch_size=64,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)"
      ],
      "metadata": {
        "id": "JRxWLJjnKUIt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 넣기 "
      ],
      "metadata": {
        "id": "1hTgHG91xbSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "   def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "       super(BasicBlock, self).__init__()\n",
        "\n",
        "\n",
        "       # ❶ 합성곱층 정의\n",
        "       self.c1 = nn.Conv2d(in_channels, out_channels, \n",
        "                           kernel_size=kernel_size, padding=1)\n",
        "       self.c2 = nn.Conv2d(out_channels, out_channels, \n",
        "                           kernel_size=kernel_size, padding=1)\n",
        "\n",
        "       self.downsample = nn.Conv2d(in_channels, out_channels, \n",
        "                                   kernel_size=1)\n",
        "       \n",
        "       # ❷ 배치 정규화층 정의\n",
        "       self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "       self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "       self.relu = nn.ReLU()\n",
        "   def forward(self, x):\n",
        "       # ❸스킵 커넥션을 위해 초기 입력을 저장\n",
        "       x_ = x\n",
        "\n",
        "       x = self.c1(x)\n",
        "       x = self.bn1(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.c2(x)\n",
        "       x = self.bn2(x)\n",
        "\n",
        "       # ➍합성곱의 결과와 입력의 채널 수를 맞춤\n",
        "       x_ = self.downsample(x_)\n",
        "\n",
        "       # ➎합성곱층의 결과와 저장해놨던 입력값을 더해줌\n",
        "       x += x_\n",
        "       x = self.relu(x)\n",
        "\n",
        "       return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "   def __init__(self, num_classes=10):\n",
        "       super(ResNet, self).__init__()\n",
        "\n",
        "\n",
        "       # ❶ 기본 블록\n",
        "       self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
        "       self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
        "       self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
        "\n",
        "\n",
        "       # ❷ 풀링을 최댓값이 아닌 평균값으로\n",
        "       self.pool = nn.AvgPool2d(kernel_size=2, stride=2) \n",
        "\n",
        "       # ❸ 분류기\n",
        "       self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n",
        "       self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
        "       self.fc3 = nn.Linear(in_features=512, out_features=num_classes)\n",
        "\n",
        "       self.relu = nn.ReLU()\n",
        "   def forward(self, x):\n",
        "       # ❶ 기본 블록과 풀링층을 통과\n",
        "       x = self.b1(x)\n",
        "       x = self.pool(x)\n",
        "       x = self.b2(x)\n",
        "       x = self.pool(x)\n",
        "       x = self.b3(x)\n",
        "       x = self.pool(x)\n",
        "\n",
        "\n",
        "       # ❷ 분류기의 입력으로 사용하기 위해 flatten\n",
        "       x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "       # ❸ 분류기로 예측값 출력\n",
        "       x = self.fc1(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.fc2(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.fc3(x)\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "NkV4EfO4VplZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet(num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "total=0 \n",
        "correct = 0"
      ],
      "metadata": {
        "id": "Os2IBshCP2bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.000001)"
      ],
      "metadata": {
        "id": "BFPIEQ-pyDL3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs= net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 750 ==749:\n",
        "      print(\"Epoch: {},Batch : {}, Loss:{}\".format(epoch+1, i+1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "      \n",
        "    if i % 1500 ==1499:\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          outputs= net(images)\n",
        "          _, predicted = torch.max(outputs.data,1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print(\"testset Accuracy  : {}\".format(100* correct/total))\n",
        "      total=0\n",
        "      correct=0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q8IufYT0P4Zx",
        "outputId": "e4cccc17-b008-47e3-dadc-3f4c1cfc76fc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1,Batch : 750, Loss:0.0047185501658915064\n",
            "Epoch: 1,Batch : 1500, Loss:0.0053353900920502205\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 1,Batch : 2250, Loss:0.004352024687174534\n",
            "Epoch: 1,Batch : 3000, Loss:0.0041504242673050485\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 1,Batch : 3750, Loss:0.004638268136292785\n",
            "Epoch: 1,Batch : 4500, Loss:0.0043626604707878314\n",
            "testset Accuracy  : 59.15\n",
            "Epoch: 1,Batch : 5250, Loss:0.005217896307643983\n",
            "Epoch: 1,Batch : 6000, Loss:0.0045637611428417735\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 1,Batch : 6750, Loss:0.004616050908451173\n",
            "Epoch: 1,Batch : 7500, Loss:0.004323120662528925\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 1,Batch : 8250, Loss:0.004461376262489302\n",
            "Epoch: 1,Batch : 9000, Loss:0.005396633175783685\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 1,Batch : 9750, Loss:0.00516167105100289\n",
            "Epoch: 1,Batch : 10500, Loss:0.0059434210818489625\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 1,Batch : 11250, Loss:0.005274467865681773\n",
            "Epoch: 2,Batch : 750, Loss:0.0037894306832524905\n",
            "Epoch: 2,Batch : 1500, Loss:0.00609218198748779\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 2,Batch : 2250, Loss:0.004621365232201534\n",
            "Epoch: 2,Batch : 3000, Loss:0.0044698931464126025\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 2,Batch : 3750, Loss:0.005486535393526906\n",
            "Epoch: 2,Batch : 4500, Loss:0.004514585715345077\n",
            "testset Accuracy  : 59.05\n",
            "Epoch: 2,Batch : 5250, Loss:0.00564490097244933\n",
            "Epoch: 2,Batch : 6000, Loss:0.0042618074586503575\n",
            "testset Accuracy  : 59.0\n",
            "Epoch: 2,Batch : 6750, Loss:0.006200160550382853\n",
            "Epoch: 2,Batch : 7500, Loss:0.0044048924939951205\n",
            "testset Accuracy  : 59.0\n",
            "Epoch: 2,Batch : 8250, Loss:0.004274980407824099\n",
            "Epoch: 2,Batch : 9000, Loss:0.005250827506766656\n",
            "testset Accuracy  : 58.95\n",
            "Epoch: 2,Batch : 9750, Loss:0.0057225583429614145\n",
            "Epoch: 2,Batch : 10500, Loss:0.004393101292374562\n",
            "testset Accuracy  : 59.05\n",
            "Epoch: 2,Batch : 11250, Loss:0.0059105564912665795\n",
            "Epoch: 3,Batch : 750, Loss:0.00479157715253347\n",
            "Epoch: 3,Batch : 1500, Loss:0.004285450635421042\n",
            "testset Accuracy  : 59.0\n",
            "Epoch: 3,Batch : 2250, Loss:0.004429696928901537\n",
            "Epoch: 3,Batch : 3000, Loss:0.0044791699498890605\n",
            "testset Accuracy  : 58.95\n",
            "Epoch: 3,Batch : 3750, Loss:0.004910814015384366\n",
            "Epoch: 3,Batch : 4500, Loss:0.005480912705987659\n",
            "testset Accuracy  : 59.0\n",
            "Epoch: 3,Batch : 5250, Loss:0.005519699976932499\n",
            "Epoch: 3,Batch : 6000, Loss:0.004740881119406326\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 3,Batch : 6750, Loss:0.0044836234981868485\n",
            "Epoch: 3,Batch : 7500, Loss:0.006110820046422128\n",
            "testset Accuracy  : 59.1\n",
            "Epoch: 3,Batch : 8250, Loss:0.005022486957586242\n",
            "Epoch: 3,Batch : 9000, Loss:0.004981202667299753\n",
            "testset Accuracy  : 59.0\n",
            "Epoch: 3,Batch : 9750, Loss:0.004788652472261082\n",
            "Epoch: 3,Batch : 10500, Loss:0.0037556331033825234\n",
            "testset Accuracy  : 59.05\n",
            "Epoch: 3,Batch : 11250, Loss:0.004734920406298817\n",
            "Epoch: 4,Batch : 750, Loss:0.005197101162051114\n",
            "Epoch: 4,Batch : 1500, Loss:0.00433204360194598\n",
            "testset Accuracy  : 59.0\n",
            "Epoch: 4,Batch : 2250, Loss:0.0055010731085381745\n",
            "Epoch: 4,Batch : 3000, Loss:0.005223574945844145\n",
            "testset Accuracy  : 59.0\n",
            "Epoch: 4,Batch : 3750, Loss:0.004955197554276053\n",
            "Epoch: 4,Batch : 4500, Loss:0.004927255629898543\n",
            "testset Accuracy  : 59.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-0a327765d6af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m                                  \"https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\")\n\u001b[1;32m    693\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarn_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks_on_exit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_end_callbacks_on_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFuture\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFuture\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pretrained 넣기\n"
      ],
      "metadata": {
        "id": "KqDJoCltxkKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/share/trained_model/cifar_resnetmine_black.pth'\n",
        "\n"
      ],
      "metadata": {
        "id": "S0fKwJo7P4iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "9VJnnqHYI-Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane','automobile','bird','cat','deer',\n",
        "           'dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "47ZGkY0NX5if"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    c= (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label= labels[i]\n",
        "      class_correct[label]+= c[i].item()\n",
        "      class_total[label]+= 1\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Accuracy of {} : {} %\".format(classes[i],100* class_correct[i]/class_total[i]))"
      ],
      "metadata": {
        "id": "QOaHVH52X5kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2bce27-7747-4d5a-ec1c-c9c133ad1616"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of plane : 68.75 %\n",
            "Accuracy of automobile : 83.33333333333333 %\n",
            "Accuracy of bird : 16.666666666666668 %\n",
            "Accuracy of cat : 58.333333333333336 %\n",
            "Accuracy of deer : 83.33333333333333 %\n",
            "Accuracy of dog : 25.0 %\n",
            "Accuracy of frog : 33.333333333333336 %\n",
            "Accuracy of horse : 41.666666666666664 %\n",
            "Accuracy of ship : 81.25 %\n",
            "Accuracy of truck : 58.333333333333336 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLanzQjcfLzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"trainset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44HdYYfb5Eja",
        "outputId": "d1a67375-5d1c-4029-9fb2-071ae14d9185"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainset Accuracy  : 99.57277777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"testset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "id": "O8NlBkmgX5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754f153f-515a-42fb-b87d-a1f991cb36ba"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset Accuracy  : 59.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "transform  = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "         transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n"
      ],
      "metadata": {
        "id": "QBkY_vX7DAOH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "testset = torchvision.datasets.ImageFolder(root = \"/content/drive/MyDrive/share/images/Statistical_Deep_Image\",\n",
        "                                           transform = transform)"
      ],
      "metadata": {
        "id": "gCPJOb-JDAOJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_loader = DataLoader(testset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)"
      ],
      "metadata": {
        "id": "IuuFxbVjDAOJ"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}