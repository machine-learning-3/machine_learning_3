{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import math\n",
        "import os"
      ],
      "metadata": {
        "id": "lTTZLf1-R2Ds"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf5031f-6659-4517-9cca-6a9d14c8da57",
        "id": "F-Uwjs7XR2Ds"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    seed = 42\n",
        "    device = \"cuda:0\"    \n",
        "        \n",
        "    lr = 1e-3\n",
        "    epochs = 25\n",
        "    batch_size = 32\n",
        "    num_workers = 4\n",
        "    train_5_folds = True\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "seed_everything(config.seed)"
      ],
      "metadata": {
        "id": "Y537CROxR2Dt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f6abcb-29ef-4507-a846-bbff358535ce",
        "id": "qn_fOyhUR2Dt"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jittering = transforms.ColorJitter(brightness = 0.4, contrast = 0.4, saturation = 0.4)\n",
        "\n",
        "\n",
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "metadata": {
        "id": "70_nXUACR2Dt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform_train1 = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                      transforms.RandomVerticalFlip(p=0.5),\n",
        "                                                  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                      transforms.RandomGrayscale(p=1)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "transform  = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),])"
      ],
      "metadata": {
        "id": "YeDYgykUR2Dt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset1 = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=True,\n",
        "                                        download=False,\n",
        "                                        transform=transform_train1)\n",
        "\n",
        "trainset2 = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=True,\n",
        "                                        download=False,\n",
        "                                        transform=transform)\n",
        "\n",
        "\n",
        "vaildset = torchvision.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=False,\n",
        "                                        download=False,\n",
        "                                        transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "trainset = trainset1 +trainset2"
      ],
      "metadata": {
        "id": "4z397PELR2Du"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.ImageFolder(root = \"/content/drive/MyDrive/share/images/Statistical_Deep_Image\",\n",
        "                                           transform = transform)"
      ],
      "metadata": {
        "id": "Zd8-9_oDSQK_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(trainset,\n",
        "                          batch_size = 32,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "vaild_loader = DataLoader(vaildset,\n",
        "                          batch_size = 64,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "test_loader = DataLoader(testset,\n",
        "                          batch_size=64,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)"
      ],
      "metadata": {
        "id": "JRxWLJjnKUIt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 넣기 "
      ],
      "metadata": {
        "id": "1hTgHG91xbSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "   def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "       super(BasicBlock, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "       self.c1 = nn.Conv2d(in_channels, out_channels, \n",
        "                           kernel_size=kernel_size, padding=1)\n",
        "       self.c2 = nn.Conv2d(out_channels, out_channels, \n",
        "                           kernel_size=kernel_size, padding=1)\n",
        "\n",
        "       self.downsample = nn.Conv2d(in_channels, out_channels, \n",
        "                                   kernel_size=1)\n",
        "       \n",
        "\n",
        "       self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "       self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "       self.relu = nn.ReLU()\n",
        "   def forward(self, x):\n",
        "       x_ = x\n",
        "\n",
        "       x = self.c1(x)\n",
        "       x = self.bn1(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.c2(x)\n",
        "       x = self.bn2(x)\n",
        "\n",
        "\n",
        "       x_ = self.downsample(x_)\n",
        "\n",
        "\n",
        "       x += x_\n",
        "       x = self.relu(x)\n",
        "\n",
        "       return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "   def __init__(self, num_classes=10):\n",
        "       super(ResNet, self).__init__()\n",
        "\n",
        "\n",
        "       self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
        "       self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
        "       self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
        "\n",
        "\n",
        "       self.pool = nn.AvgPool2d(kernel_size=2, stride=2) \n",
        "\n",
        "       self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n",
        "       self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
        "       self.fc3 = nn.Linear(in_features=512, out_features=num_classes)\n",
        "\n",
        "       self.relu = nn.ReLU()\n",
        "   def forward(self, x):\n",
        "       x = self.b1(x)\n",
        "       x = self.pool(x)\n",
        "       x = self.b2(x)\n",
        "       x = self.pool(x)\n",
        "       x = self.b3(x)\n",
        "       x = self.pool(x)\n",
        "\n",
        "       x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "       x = self.fc1(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.fc2(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.fc3(x)\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "NkV4EfO4VplZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = ResNet(num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "total=0 \n",
        "correct = 0"
      ],
      "metadata": {
        "id": "Os2IBshCP2bO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "BFPIEQ-pyDL3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs= net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 750 ==749:\n",
        "      print(\"Epoch: {},Batch : {}, Loss:{}\".format(epoch+1, i+1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "    if i %1500 ==1499:\n",
        "      with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        for k, data1 in enumerate(vaild_loader, 0):\n",
        "          val_inputs, val_label = data1[0].to(device), data1[1].to(device)\n",
        "          val_output = net(val_inputs)\n",
        "          v_loss = criterion(val_output, val_label)\n",
        "          val_loss += v_loss\n",
        "          _, predicted = torch.max(val_output.data,1)\n",
        "          total += val_label.size(0)\n",
        "          correct += (predicted == val_label).sum().item()\n",
        "      print(\"validation loss {}\".format(val_loss))\n",
        "      print(\"vaildset Accuracy  : {}\".format(100* correct/total))\n",
        "      total=0\n",
        "      correct=0\n",
        "      with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          outputs= net(images)\n",
        "          _, predicted = torch.max(outputs.data,1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print(\"testset Accuracy  : {}\".format(100* correct/total))\n",
        "      total=0\n",
        "      correct=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q8IufYT0P4Zx",
        "outputId": "c8abc802-86ed-4c23-8a95-1a491d641619"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1,Batch : 750, Loss:0.01611057377367979\n",
            "Epoch: 1,Batch : 1500, Loss:0.0130853780308571\n",
            "validation loss 141.38055419921875\n",
            "vaildset Accuracy  : 84.86\n",
            "testset Accuracy  : 54.15\n",
            "Epoch: 1,Batch : 2250, Loss:0.012356583467555993\n",
            "Epoch: 1,Batch : 3000, Loss:0.009904100524613569\n",
            "validation loss 139.92495727539062\n",
            "vaildset Accuracy  : 85.1\n",
            "testset Accuracy  : 53.45\n",
            "Epoch: 2,Batch : 750, Loss:0.007910461362995648\n",
            "Epoch: 2,Batch : 1500, Loss:0.00837292145057063\n",
            "validation loss 144.1121826171875\n",
            "vaildset Accuracy  : 85.12\n",
            "testset Accuracy  : 54.0\n",
            "Epoch: 2,Batch : 2250, Loss:0.009375771340030951\n",
            "Epoch: 2,Batch : 3000, Loss:0.006920369636329951\n",
            "validation loss 148.62342834472656\n",
            "vaildset Accuracy  : 85.32\n",
            "testset Accuracy  : 54.8\n",
            "Epoch: 3,Batch : 750, Loss:0.006774282088605333\n",
            "Epoch: 3,Batch : 1500, Loss:0.005991956056035178\n",
            "validation loss 151.4351348876953\n",
            "vaildset Accuracy  : 85.34\n",
            "testset Accuracy  : 54.4\n",
            "Epoch: 3,Batch : 2250, Loss:0.006040144728802261\n",
            "Epoch: 3,Batch : 3000, Loss:0.006174122286297006\n",
            "validation loss 151.5413055419922\n",
            "vaildset Accuracy  : 85.39\n",
            "testset Accuracy  : 54.3\n",
            "Epoch: 4,Batch : 750, Loss:0.0061611573507834696\n",
            "Epoch: 4,Batch : 1500, Loss:0.005299801695075757\n",
            "validation loss 153.91700744628906\n",
            "vaildset Accuracy  : 85.18\n",
            "testset Accuracy  : 54.65\n",
            "Epoch: 4,Batch : 2250, Loss:0.004941715783344989\n",
            "Epoch: 4,Batch : 3000, Loss:0.005578968163915306\n",
            "validation loss 158.05712890625\n",
            "vaildset Accuracy  : 85.4\n",
            "testset Accuracy  : 54.65\n",
            "Epoch: 5,Batch : 750, Loss:0.004684006692407795\n",
            "Epoch: 5,Batch : 1500, Loss:0.0036479801466659297\n",
            "validation loss 158.44357299804688\n",
            "vaildset Accuracy  : 85.51\n",
            "testset Accuracy  : 55.35\n",
            "Epoch: 5,Batch : 2250, Loss:0.004323700268976267\n",
            "Epoch: 5,Batch : 3000, Loss:0.004861890627632505\n",
            "validation loss 159.97789001464844\n",
            "vaildset Accuracy  : 85.31\n",
            "testset Accuracy  : 54.9\n",
            "Epoch: 6,Batch : 750, Loss:0.0033326335643862493\n",
            "Epoch: 6,Batch : 1500, Loss:0.00403099881074354\n",
            "validation loss 167.5344696044922\n",
            "vaildset Accuracy  : 85.46\n",
            "testset Accuracy  : 54.25\n",
            "Epoch: 6,Batch : 2250, Loss:0.002826981307547129\n",
            "Epoch: 6,Batch : 3000, Loss:0.0035403528302149637\n",
            "validation loss 169.5116424560547\n",
            "vaildset Accuracy  : 85.15\n",
            "testset Accuracy  : 54.5\n",
            "Epoch: 7,Batch : 750, Loss:0.0028892277617404145\n",
            "Epoch: 7,Batch : 1500, Loss:0.003505758104754477\n",
            "validation loss 174.74119567871094\n",
            "vaildset Accuracy  : 85.47\n",
            "testset Accuracy  : 54.9\n",
            "Epoch: 7,Batch : 2250, Loss:0.0034320865638894416\n",
            "Epoch: 7,Batch : 3000, Loss:0.0028053799629578647\n",
            "validation loss 175.18247985839844\n",
            "vaildset Accuracy  : 85.32\n",
            "testset Accuracy  : 54.95\n",
            "Epoch: 8,Batch : 750, Loss:0.0023811181713830083\n",
            "Epoch: 8,Batch : 1500, Loss:0.002761433662254433\n",
            "validation loss 178.81690979003906\n",
            "vaildset Accuracy  : 85.51\n",
            "testset Accuracy  : 55.3\n",
            "Epoch: 8,Batch : 2250, Loss:0.002909626209229856\n",
            "Epoch: 8,Batch : 3000, Loss:0.0017819886137081652\n",
            "validation loss 181.95748901367188\n",
            "vaildset Accuracy  : 85.29\n",
            "testset Accuracy  : 54.85\n",
            "Epoch: 9,Batch : 750, Loss:0.002516231618388712\n",
            "Epoch: 9,Batch : 1500, Loss:0.0022491301022119\n",
            "validation loss 187.82559204101562\n",
            "vaildset Accuracy  : 85.16\n",
            "testset Accuracy  : 55.3\n",
            "Epoch: 9,Batch : 2250, Loss:0.0018903260444378845\n",
            "Epoch: 9,Batch : 3000, Loss:0.0022151777151324177\n",
            "validation loss 189.15638732910156\n",
            "vaildset Accuracy  : 85.74\n",
            "testset Accuracy  : 55.4\n",
            "Epoch: 10,Batch : 750, Loss:0.0016154701294927207\n",
            "Epoch: 10,Batch : 1500, Loss:0.0016944195184978171\n",
            "validation loss 198.63412475585938\n",
            "vaildset Accuracy  : 85.47\n",
            "testset Accuracy  : 54.3\n",
            "Epoch: 10,Batch : 2250, Loss:0.0016488064365435377\n",
            "Epoch: 10,Batch : 3000, Loss:0.0018783915543036187\n",
            "validation loss 202.80502319335938\n",
            "vaildset Accuracy  : 85.38\n",
            "testset Accuracy  : 55.4\n",
            "Epoch: 11,Batch : 750, Loss:0.0021034240353200884\n",
            "Epoch: 11,Batch : 1500, Loss:0.001764291367650131\n",
            "validation loss 201.0034942626953\n",
            "vaildset Accuracy  : 85.24\n",
            "testset Accuracy  : 54.9\n",
            "Epoch: 11,Batch : 2250, Loss:0.001845004226620226\n",
            "Epoch: 11,Batch : 3000, Loss:0.00197505144231323\n",
            "validation loss 200.3950958251953\n",
            "vaildset Accuracy  : 85.22\n",
            "testset Accuracy  : 55.55\n",
            "Epoch: 12,Batch : 750, Loss:0.001646705627960408\n",
            "Epoch: 12,Batch : 1500, Loss:0.0013234107119588217\n",
            "validation loss 207.02847290039062\n",
            "vaildset Accuracy  : 85.53\n",
            "testset Accuracy  : 54.55\n",
            "Epoch: 12,Batch : 2250, Loss:0.001241721847449476\n",
            "Epoch: 12,Batch : 3000, Loss:0.001130516486733098\n",
            "validation loss 215.96238708496094\n",
            "vaildset Accuracy  : 85.56\n",
            "testset Accuracy  : 55.6\n",
            "Epoch: 13,Batch : 750, Loss:0.0009783170020485027\n",
            "Epoch: 13,Batch : 1500, Loss:0.001286026465702001\n",
            "validation loss 216.0407257080078\n",
            "vaildset Accuracy  : 85.36\n",
            "testset Accuracy  : 55.45\n",
            "Epoch: 13,Batch : 2250, Loss:0.0011550607672042564\n",
            "Epoch: 13,Batch : 3000, Loss:0.0012186981524708802\n",
            "validation loss 224.79627990722656\n",
            "vaildset Accuracy  : 85.39\n",
            "testset Accuracy  : 55.85\n",
            "Epoch: 14,Batch : 750, Loss:0.000720704022180266\n",
            "Epoch: 14,Batch : 1500, Loss:0.0009409431213290586\n",
            "validation loss 226.29666137695312\n",
            "vaildset Accuracy  : 85.63\n",
            "testset Accuracy  : 55.15\n",
            "Epoch: 14,Batch : 2250, Loss:0.0010124535383507203\n",
            "Epoch: 14,Batch : 3000, Loss:0.0008886753337713955\n",
            "validation loss 238.43467712402344\n",
            "vaildset Accuracy  : 85.23\n",
            "testset Accuracy  : 55.35\n",
            "Epoch: 15,Batch : 750, Loss:0.000860342237433398\n",
            "Epoch: 15,Batch : 1500, Loss:0.0008291014757136107\n",
            "validation loss 242.2320556640625\n",
            "vaildset Accuracy  : 85.46\n",
            "testset Accuracy  : 55.25\n",
            "Epoch: 15,Batch : 2250, Loss:0.0013982691019866803\n",
            "Epoch: 15,Batch : 3000, Loss:0.0008976778400067731\n",
            "validation loss 232.49497985839844\n",
            "vaildset Accuracy  : 85.45\n",
            "testset Accuracy  : 55.7\n",
            "Epoch: 16,Batch : 750, Loss:0.001126296655604945\n",
            "Epoch: 16,Batch : 1500, Loss:0.0009701958758704555\n",
            "validation loss 227.7347412109375\n",
            "vaildset Accuracy  : 85.44\n",
            "testset Accuracy  : 55.3\n",
            "Epoch: 16,Batch : 2250, Loss:0.0005113883838221262\n",
            "Epoch: 16,Batch : 3000, Loss:0.000886502727031972\n",
            "validation loss 237.49977111816406\n",
            "vaildset Accuracy  : 85.28\n",
            "testset Accuracy  : 54.95\n",
            "Epoch: 17,Batch : 750, Loss:0.0005520772248439026\n",
            "Epoch: 17,Batch : 1500, Loss:0.0005710197522504942\n",
            "validation loss 245.46514892578125\n",
            "vaildset Accuracy  : 85.57\n",
            "testset Accuracy  : 54.5\n",
            "Epoch: 17,Batch : 2250, Loss:0.000566214507667718\n",
            "Epoch: 17,Batch : 3000, Loss:0.0007116255223168684\n",
            "validation loss 243.19677734375\n",
            "vaildset Accuracy  : 85.58\n",
            "testset Accuracy  : 55.0\n",
            "Epoch: 18,Batch : 750, Loss:0.0004954981919048213\n",
            "Epoch: 18,Batch : 1500, Loss:0.00047096221009315154\n",
            "validation loss 251.95127868652344\n",
            "vaildset Accuracy  : 85.64\n",
            "testset Accuracy  : 55.45\n",
            "Epoch: 18,Batch : 2250, Loss:0.0004119981944766544\n",
            "Epoch: 18,Batch : 3000, Loss:0.00037597836706999675\n",
            "validation loss 254.93115234375\n",
            "vaildset Accuracy  : 85.53\n",
            "testset Accuracy  : 54.5\n",
            "Epoch: 19,Batch : 750, Loss:0.0005458969188834643\n",
            "Epoch: 19,Batch : 1500, Loss:0.0006877814903239444\n",
            "validation loss 258.4452209472656\n",
            "vaildset Accuracy  : 85.27\n",
            "testset Accuracy  : 55.0\n",
            "Epoch: 19,Batch : 2250, Loss:0.0005391849227390895\n",
            "Epoch: 19,Batch : 3000, Loss:0.0008572652287351183\n",
            "validation loss 253.3236083984375\n",
            "vaildset Accuracy  : 85.44\n",
            "testset Accuracy  : 54.55\n",
            "Epoch: 20,Batch : 750, Loss:0.0006739652598529659\n",
            "Epoch: 20,Batch : 1500, Loss:0.0006911866444367626\n",
            "validation loss 255.48748779296875\n",
            "vaildset Accuracy  : 85.49\n",
            "testset Accuracy  : 54.9\n",
            "Epoch: 20,Batch : 2250, Loss:0.00038974324263490887\n",
            "Epoch: 20,Batch : 3000, Loss:0.0006174869573095555\n",
            "validation loss 265.23345947265625\n",
            "vaildset Accuracy  : 85.33\n",
            "testset Accuracy  : 54.95\n",
            "Epoch: 21,Batch : 750, Loss:0.00015242161494933993\n",
            "Epoch: 21,Batch : 1500, Loss:0.0005291289137216541\n",
            "validation loss 268.6285400390625\n",
            "vaildset Accuracy  : 85.42\n",
            "testset Accuracy  : 55.0\n",
            "Epoch: 21,Batch : 2250, Loss:0.0007184685116281098\n",
            "Epoch: 21,Batch : 3000, Loss:0.00025579445957885837\n",
            "validation loss 267.73065185546875\n",
            "vaildset Accuracy  : 85.6\n",
            "testset Accuracy  : 55.15\n",
            "Epoch: 22,Batch : 750, Loss:0.0003025176904830841\n",
            "Epoch: 22,Batch : 1500, Loss:0.00036373657466859133\n",
            "validation loss 274.90869140625\n",
            "vaildset Accuracy  : 85.5\n",
            "testset Accuracy  : 55.25\n",
            "Epoch: 22,Batch : 2250, Loss:0.00038563122892615597\n",
            "Epoch: 22,Batch : 3000, Loss:0.000468301313540458\n",
            "validation loss 286.5040283203125\n",
            "vaildset Accuracy  : 85.45\n",
            "testset Accuracy  : 55.65\n",
            "Epoch: 23,Batch : 750, Loss:0.00045410749564492813\n",
            "Epoch: 23,Batch : 1500, Loss:0.0007712623532167175\n",
            "validation loss 266.8266296386719\n",
            "vaildset Accuracy  : 85.72\n",
            "testset Accuracy  : 56.0\n",
            "Epoch: 23,Batch : 2250, Loss:0.0004238080194332875\n",
            "Epoch: 23,Batch : 3000, Loss:0.0010697875371350988\n",
            "validation loss 263.687255859375\n",
            "vaildset Accuracy  : 85.38\n",
            "testset Accuracy  : 55.7\n",
            "Epoch: 24,Batch : 750, Loss:0.0004476942028417186\n",
            "Epoch: 24,Batch : 1500, Loss:0.000328115007865471\n",
            "validation loss 272.11181640625\n",
            "vaildset Accuracy  : 85.58\n",
            "testset Accuracy  : 55.15\n",
            "Epoch: 24,Batch : 2250, Loss:0.0004506004889109856\n",
            "Epoch: 24,Batch : 3000, Loss:0.0002831015700103808\n",
            "validation loss 273.9531555175781\n",
            "vaildset Accuracy  : 85.42\n",
            "testset Accuracy  : 55.4\n",
            "Epoch: 25,Batch : 750, Loss:0.00046669256134885097\n",
            "Epoch: 25,Batch : 1500, Loss:0.0004298931552127645\n",
            "validation loss 279.6895751953125\n",
            "vaildset Accuracy  : 85.37\n",
            "testset Accuracy  : 55.3\n",
            "Epoch: 25,Batch : 2250, Loss:0.0002793834770803463\n",
            "Epoch: 25,Batch : 3000, Loss:0.00021842945231964606\n",
            "validation loss 284.8119201660156\n",
            "vaildset Accuracy  : 85.51\n",
            "testset Accuracy  : 55.1\n",
            "Epoch: 26,Batch : 750, Loss:0.00035726473672261525\n",
            "Epoch: 26,Batch : 1500, Loss:0.0003821674378631045\n",
            "validation loss 289.887451171875\n",
            "vaildset Accuracy  : 85.14\n",
            "testset Accuracy  : 54.95\n",
            "Epoch: 26,Batch : 2250, Loss:0.000376688544197765\n",
            "Epoch: 26,Batch : 3000, Loss:0.0003685061640078494\n",
            "validation loss 285.15972900390625\n",
            "vaildset Accuracy  : 85.57\n",
            "testset Accuracy  : 54.45\n",
            "Epoch: 27,Batch : 750, Loss:0.000178973598833961\n",
            "Epoch: 27,Batch : 1500, Loss:0.00017803591643907168\n",
            "validation loss 290.7261047363281\n",
            "vaildset Accuracy  : 85.61\n",
            "testset Accuracy  : 55.0\n",
            "Epoch: 27,Batch : 2250, Loss:0.0004302938266253075\n",
            "Epoch: 27,Batch : 3000, Loss:0.00029756916148940325\n",
            "validation loss 289.47698974609375\n",
            "vaildset Accuracy  : 85.54\n",
            "testset Accuracy  : 54.95\n",
            "Epoch: 28,Batch : 750, Loss:0.0003160366354380135\n",
            "Epoch: 28,Batch : 1500, Loss:0.00017799230738842976\n",
            "validation loss 290.47808837890625\n",
            "vaildset Accuracy  : 85.56\n",
            "testset Accuracy  : 55.65\n",
            "Epoch: 28,Batch : 2250, Loss:0.0002422087526371308\n",
            "Epoch: 28,Batch : 3000, Loss:0.00025899265455119557\n",
            "validation loss 293.27117919921875\n",
            "vaildset Accuracy  : 85.34\n",
            "testset Accuracy  : 55.15\n",
            "Epoch: 29,Batch : 750, Loss:0.0003720868879298759\n",
            "Epoch: 29,Batch : 1500, Loss:0.0008169052736589542\n",
            "validation loss 296.9412841796875\n",
            "vaildset Accuracy  : 85.32\n",
            "testset Accuracy  : 55.4\n",
            "Epoch: 29,Batch : 2250, Loss:0.0002889485466946825\n",
            "Epoch: 29,Batch : 3000, Loss:0.00026754753963896804\n",
            "validation loss 301.64910888671875\n",
            "vaildset Accuracy  : 85.39\n",
            "testset Accuracy  : 54.95\n",
            "Epoch: 30,Batch : 750, Loss:0.00024768941273346166\n",
            "Epoch: 30,Batch : 1500, Loss:0.0001597545055897005\n",
            "validation loss 311.8084411621094\n",
            "vaildset Accuracy  : 85.72\n",
            "testset Accuracy  : 55.4\n",
            "Epoch: 30,Batch : 2250, Loss:9.53557044592106e-05\n",
            "Epoch: 30,Batch : 3000, Loss:0.00037334137573520154\n",
            "validation loss 302.58831787109375\n",
            "vaildset Accuracy  : 85.36\n",
            "testset Accuracy  : 55.2\n",
            "Epoch: 31,Batch : 750, Loss:0.00038377631257617795\n",
            "Epoch: 31,Batch : 1500, Loss:0.0002714870613121185\n",
            "validation loss 304.7171936035156\n",
            "vaildset Accuracy  : 85.39\n",
            "testset Accuracy  : 55.3\n",
            "Epoch: 31,Batch : 2250, Loss:0.0002614127550263532\n",
            "Epoch: 31,Batch : 3000, Loss:0.00033493773806443595\n",
            "validation loss 306.8631591796875\n",
            "vaildset Accuracy  : 85.26\n",
            "testset Accuracy  : 55.5\n",
            "Epoch: 32,Batch : 750, Loss:0.00035805542423757066\n",
            "Epoch: 32,Batch : 1500, Loss:0.0003769499005338829\n",
            "validation loss 311.7944641113281\n",
            "vaildset Accuracy  : 85.43\n",
            "testset Accuracy  : 54.85\n",
            "Epoch: 32,Batch : 2250, Loss:0.00021726807878206744\n",
            "Epoch: 32,Batch : 3000, Loss:0.0003305334905341734\n",
            "validation loss 315.1856384277344\n",
            "vaildset Accuracy  : 85.57\n",
            "testset Accuracy  : 55.3\n",
            "Epoch: 33,Batch : 750, Loss:0.00023739752614518206\n",
            "Epoch: 33,Batch : 1500, Loss:0.0005151863774382562\n",
            "validation loss 318.17962646484375\n",
            "vaildset Accuracy  : 85.52\n",
            "testset Accuracy  : 55.25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7fca13add8e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    169\u001b[0m                  \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                  \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foreach'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                  capturable=group['capturable'])\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    224\u001b[0m          \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m          \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m          capturable=capturable)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pretrained 넣기\n"
      ],
      "metadata": {
        "id": "KqDJoCltxkKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/share/trained_model/cifar_resnetmine.pth'\n",
        "\n"
      ],
      "metadata": {
        "id": "S0fKwJo7P4iQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "9VJnnqHYI-Bm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane','automobile','bird','cat','deer',\n",
        "           'dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "47ZGkY0NX5if"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    c= (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label= labels[i]\n",
        "      class_correct[label]+= c[i].item()\n",
        "      class_total[label]+= 1\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Accuracy of {} : {} %\".format(classes[i],100* class_correct[i]/class_total[i]))"
      ],
      "metadata": {
        "id": "QOaHVH52X5kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c92ed2ec-d466-4c75-d25d-8602b6c2595d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of plane : 81.25 %\n",
            "Accuracy of automobile : 58.333333333333336 %\n",
            "Accuracy of bird : 33.333333333333336 %\n",
            "Accuracy of cat : 33.333333333333336 %\n",
            "Accuracy of deer : 66.66666666666667 %\n",
            "Accuracy of dog : 25.0 %\n",
            "Accuracy of frog : 25.0 %\n",
            "Accuracy of horse : 33.333333333333336 %\n",
            "Accuracy of ship : 68.75 %\n",
            "Accuracy of truck : 58.333333333333336 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLanzQjcfLzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"trainset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44HdYYfb5Eja",
        "outputId": "fc5904e5-e935-4edf-8921-7cbf755c60c1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainset Accuracy  : 99.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= net(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    total +=labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"testset Accuracy  : {}\".format(100* correct/total))"
      ],
      "metadata": {
        "id": "O8NlBkmgX5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238e6889-a5bf-4ece-ad5f-bfb0275a8796"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset Accuracy  : 55.15\n"
          ]
        }
      ]
    }
  ]
}