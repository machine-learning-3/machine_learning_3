{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gtydA85b-adR"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets as ds\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms as ts\n",
        "import torchvision as tv\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.backends.cudnn as cudnn\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "%config Completer.use_jedi = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy"
      ],
      "metadata": {
        "id": "Q50Tu5dK-0hC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets as ds\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms as ts\n",
        "import torchvision as tv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.backends.cudnn as cudnn\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "\n",
        "%config Completer.use_jedi = False"
      ],
      "metadata": {
        "id": "W3twMatO-0kA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setseed(seednum = 20):\n",
        "    torch.manual_seed(seednum)\n",
        "    torch.cuda.manual_seed(seednum)\n",
        "    torch.cuda.manual_seed_all(seednum)\n",
        "    np.random.seed(seednum)\n",
        "    cudnn.benchmark = False\n",
        "    cudnn.deterministic = True\n",
        "    random.seed(seednum)"
      ],
      "metadata": {
        "id": "GbhOx3MW-5I5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setseed(35)"
      ],
      "metadata": {
        "id": "6hDXlnxB-5LT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCTMnkHS-5N0",
        "outputId": "f486bc9f-a2a5-4db2-c47d-328282c7ac2a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = ts.Compose([ts.ToTensor(),\n",
        "                                      ts.RandomHorizontalFlip(p=0.2),\n",
        "                                      ts.RandomVerticalFlip(p=0.2),\n",
        "                                      ts.RandomGrayscale(p=0.2)\n",
        "                                     ])\n",
        "\n",
        "transform_validation = ts.Compose([\n",
        "        ts.ToTensor(),\n",
        "        ts.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "transform  = ts.Compose([\n",
        "        ts.ToTensor(),\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "HheEnG4A-5P7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_aug2 = ts.Compose(\n",
        "    [\n",
        "        ts.ToTensor(),\n",
        "        ts.RandomApply([ts.RandomResizedCrop((32, 32), scale=(0.1, 1), ratio=(0.5, 2)),\n",
        "        ts.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)], p=0.9)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "DuEqSVjU-5Sf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset1 = tv.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform_train)\n",
        "\n",
        "vaildset = tv.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=False,\n",
        "                                        download=True,\n",
        "                                        transform=transform_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeGI8wr3_Ai4",
        "outputId": "d6e642a5-50c7-41f9-b584-d58bf67acbc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset2 = tv.datasets.CIFAR10(root='/content/drive/MyDrive/share/cafir_10',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform_aug2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx5NnZ_B_AlQ",
        "outputId": "cd1af62e-7a1d-4b93-95e9-77bc3dc166d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = trainset1+trainset2"
      ],
      "metadata": {
        "id": "DwN7yfzO_An0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset = tv.datasets.ImageFolder(root = \"/content/drive/MyDrive/images/Statistical_Deep_Image\",\n",
        "                                            transform = transform)"
      ],
      "metadata": {
        "id": "bjxpjMqI_Apv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(trainset,\n",
        "                          batch_size = 32,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "vaild_loader = DataLoader(vaildset,\n",
        "                          batch_size = 32,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)\n",
        "\n",
        "\n",
        "test_loader = DataLoader(testset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)"
      ],
      "metadata": {
        "id": "LTM3_DLS_Asg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(testset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)"
      ],
      "metadata": {
        "id": "1jirNfA3Av_h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IdentityPadding(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(IdentityPadding, self).__init__()\n",
        "\n",
        "        if stride == 2:\n",
        "            self.pooling = nn.AvgPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
        "        else:\n",
        "            self.pooling = None\n",
        "            \n",
        "        self.add_channels = out_channels - in_channels\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = F.pad(x, (0, 0, 0, 0, 0, self.add_channels))\n",
        "        if self.pooling is not None:\n",
        "            out = self.pooling(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
        "                                stride=stride, padding=1, bias=False)      \n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n",
        "                                stride=1, padding=1, bias=False)    \n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.down_sample = IdentityPadding(in_channels, out_channels, stride)\n",
        "            \n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = self.down_sample(x)\n",
        "        out = self.bn1(x)\n",
        "        out = self.conv1(out)        \n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn3(out)\n",
        "       \n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "\n",
        "class PyramidNet(nn.Module):\n",
        "    def __init__(self, num_layers, alpha, block, num_classes=10):\n",
        "        super(PyramidNet, self).__init__()   \t\n",
        "        self.in_channels = 16\n",
        "        \n",
        "        # num_layers = (110 - 2)/6 = 18\n",
        "        self.num_layers = num_layers\n",
        "        self.addrate = alpha / (3*self.num_layers*1.0)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, \n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        # feature map size = 32x32\n",
        "        self.layer1 = self.get_layers(block, stride=1)\n",
        "        # feature map size = 16x16\n",
        "        self.layer2 = self.get_layers(block, stride=2)\n",
        "        # feature map size = 8x8\n",
        "        self.layer3 = self.get_layers(block, stride=2)\n",
        "\n",
        "        self.out_channels = int(round(self.out_channels))\n",
        "        self.bn_out= nn.BatchNorm2d(self.out_channels)\n",
        "        self.relu_out = nn.ReLU(inplace=True)\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "        self.fc_out = nn.Linear(self.out_channels, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', \n",
        "                                        nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def get_layers(self, block, stride):\n",
        "        layers_list = []\n",
        "        for _ in range(self.num_layers - 1):\n",
        "            self.out_channels = self.in_channels + self.addrate\n",
        "            layers_list.append(block(int(round(self.in_channels)), \n",
        "                                     int(round(self.out_channels)), \n",
        "                                     stride))\n",
        "            self.in_channels = self.out_channels\n",
        "            stride=1\n",
        "\n",
        "        return nn.Sequential(*layers_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.bn_out(x)\n",
        "        x = self.relu_out(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def pyramidnet():\n",
        "    block = ResidualBlock\n",
        "    model = PyramidNet(num_layers=18, alpha=48, block=block)\n",
        "    return model"
      ],
      "metadata": {
        "id": "rtkCFf1A_Jj7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pyramidnet()"
      ],
      "metadata": {
        "id": "Mt6eHlae_Jmy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "pHgYRZsF_Jop"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=8)\n",
        "\n",
        "\n",
        "# get current lr\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "# calculate the metric per mini-batch\n",
        "def metric_batch(output, target):\n",
        "    pred = output.argmax(1, keepdim=True)\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "\n",
        "# calculate the loss per mini-batch\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss_b = loss_func(output, target)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "    \n",
        "    return loss_b.item(), metric_b\n",
        "\n",
        "\n",
        "# calculate the loss per epochs\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        output = model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        running_loss += loss_b\n",
        "        \n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    loss = running_loss / len_data\n",
        "    metric = running_metric / len_data\n",
        "    return loss, metric\n",
        "\n",
        "\n",
        "# function to start training\n",
        "def train_val(model, params):\n",
        "    num_epochs=params['num_epochs']\n",
        "    loss_func=params['loss_func']\n",
        "    opt=params['optimizer']\n",
        "    train_dl=params['train_dl']\n",
        "    val_dl=params['val_dl']\n",
        "    sanity_check=params['sanity_check']\n",
        "    lr_scheduler=params['lr_scheduler']\n",
        "    path2weights=params['path2weights']\n",
        "\n",
        "    loss_history = {'train': [], 'val': []}\n",
        "    metric_history = {'train': [], 'val': []}\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "        loss_history['val'].append(val_loss)\n",
        "        metric_history['val'].append(val_metric)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), path2weights)\n",
        "            print('Copied best model weights!')\n",
        "\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            print('Loading best model weights!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "        print('-'*10)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history"
      ],
      "metadata": {
        "id": "xmFXcsHe_JrQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_train = {\n",
        "    'num_epochs':4,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_loader,\n",
        "    'val_dl':vaild_loader,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./drive/MyDrive/models_pyramidnet_7/weights.pt',\n",
        "}\n",
        "\n",
        "# check the directory to save weights.pt\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./drive/MyDrive/models_pyramidnet_7')"
      ],
      "metadata": {
        "id": "GoKydkEZ_JtQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B60Hqdi0_Jvy",
        "outputId": "0576aa8e-8ad0-40c6-a132-fba4533392b2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/3, current lr= 0.0001\n",
            "Copied best model weights!\n",
            "train loss: 0.374754, val loss: 0.274920, accuracy: 91.27, time: 8.0215 min\n",
            "----------\n",
            "Epoch 1/3, current lr= 0.0001\n",
            "Copied best model weights!\n",
            "train loss: 0.368155, val loss: 0.274855, accuracy: 91.03, time: 16.0603 min\n",
            "----------\n",
            "Epoch 2/3, current lr= 0.0001\n",
            "Copied best model weights!\n",
            "train loss: 0.368189, val loss: 0.272520, accuracy: 91.15, time: 24.0342 min\n",
            "----------\n",
            "Epoch 3/3, current lr= 0.0001\n",
            "Copied best model weights!\n",
            "train loss: 0.369697, val loss: 0.268819, accuracy: 91.28, time: 32.0072 min\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5P__NIAZR0o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/models_pyramidnet_6/weights.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_1f6KGp_V_g",
        "outputId": "a452d2ee-5d61-481c-f049-eb042d268606"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liE_xTSn_WCW",
        "outputId": "46433fda-bb29-4f6b-fe00-2927ad19240f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PyramidNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(16, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(17, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(17, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(18, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(19, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (3): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(19, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (4): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (5): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(20, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (6): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(21, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(22, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (7): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(22, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(23, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (8): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(23, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (9): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(24, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (10): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(25, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (11): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(26, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(27, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (12): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(27, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (13): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (14): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(28, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(29, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (15): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(29, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (16): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(30, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(31, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding(\n",
              "        (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(32, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(33, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(33, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(34, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (3): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(34, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(35, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (4): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(35, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (5): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (6): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(36, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(37, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (7): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(37, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (8): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(38, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(39, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (9): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(39, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (10): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(40, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(41, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (11): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(41, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(42, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (12): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(42, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(43, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (13): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(43, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (14): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (15): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(44, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (16): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(45, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(46, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(46, 47, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(47, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding(\n",
              "        (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(47, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(48, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(49, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (3): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(49, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (4): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(50, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (5): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(51, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (6): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (7): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(52, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(53, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (8): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(53, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (9): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(54, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (10): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(55, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (11): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(56, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(57, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (12): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(57, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (13): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(58, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(59, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (14): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(59, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (15): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "    (16): ResidualBlock(\n",
              "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(60, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(61, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (down_sample): IdentityPadding()\n",
              "    )\n",
              "  )\n",
              "  (bn_out): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu_out): ReLU(inplace=True)\n",
              "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "  (fc_out): Linear(in_features=61, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs= model(images)\n",
        "      _, predicted = torch.max(outputs.data,1)\n",
        "      total +=labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(100* correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DibenrPc_bEC",
        "outputId": "64d6dd50-f734-4ef5-d3b2-96220081733b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72.26386806596702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs= model(images)\n",
        "      _, predicted = torch.max(outputs.data,1)\n",
        "      total +=labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(100* correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWZBE1GoRU-X",
        "outputId": "05b35321-c034-411d-a97e-1f193f1d8603"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71.56421789105447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "J9QwxA_bEugI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "eQpwHDeSE_n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation set classification"
      ],
      "metadata": {
        "id": "80LsAAzdFALP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in vaild_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= model(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    c= (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label= labels[i]\n",
        "      class_correct[label]+= c[i].item()\n",
        "      class_total[label]+= 1\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Accuracy of {} : {} %\".format(classes[i],100* class_correct[i]/class_total[i]))"
      ],
      "metadata": {
        "id": "k8lvFTmJEpcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test set classifcation"
      ],
      "metadata": {
        "id": "RszCssATFIan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs= model(images)\n",
        "    _, predicted = torch.max(outputs.data,1)\n",
        "    c= (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label= labels[i]\n",
        "      class_correct[label]+= c[i].item()\n",
        "      class_total[label]+= 1\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Accuracy of {} : {} %\".format(classes[i],100* class_correct[i]/class_total[i]))"
      ],
      "metadata": {
        "id": "6dNMRv1XEpiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):    # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Upcf2phhGI1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input):\n",
        "    out = model(input.reshape(1, 3, 32, 32))\n",
        "    _, pred = torch.max(out, dim=1)\n",
        "    return classes[pred]\n",
        "\n",
        "def check_sample(img_label_pair):\n",
        "    imshow(img_label_pair[0])\n",
        "    print(\"Predicted: \" + predict(img_label_pair[0]))\n",
        "    print(\"Desired output: \" + classes[img_label_pair[1]])"
      ],
      "metadata": {
        "id": "z_rMTX5nGI3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m8CZAt2rGVuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q9VD1IvDGVwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uj5cDlSyGI5g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}